# Report from the Point of View of 1997 

## Introduction

In the 1950s, a geochemist, Charles David Keeling, began to collect air samples to measure the amount of carbon dioxide in the air, and these measurements would become his life's work. His initial samples indicated that the air contained more CO2 at night compared to the daytime. This finding suggested that plants absorbed CO2 during the day and released CO2 during the evening. Over time, his measurements showed a seasonal cycle, which was consistent with the seasonal patterns of terrestrial vegetation, and the CO2 data also would persistently increase over time. This rise in CO2 prompted questions about preconceived notions around the ocean's ability to absorb CO2 emitted by fossil fuels. If CO2 released by coal, natural gas, and petroleum remained in the air, this could account for the rise in CO2 over the years. 

This finding is incredibly important, because the rising rate of CO2 has implications on the Earth's ability to release heat from the atmosphere. If heat isn't able to escape, then this would subsequently result in a warmer climate, which would become known as the "greenhouse effect". However, while the CO2 data demonstrated a clear upward trend over time, it was also marked by periods of decline which could not solely be attributed to plant growth seasonality. A deeper investigation revealed that El Nino weather patterns affected the amount of CO2 that was released in the air by vegetation and soils. Over time, the data would also show earlier seasonal starts, and when this data was layered with temperature data, it had become clear that the concerns of a warming planet years earlier were starting to manifest itself within the data. Since this connection has been established between rising CO2 and corresponding global temperatures, more attention has surrounded the topics of global warming and climate change. As a result, business and political decision makers are starting to incorporate this data into their longer-term strategies; however, their pace of action may be too slow to prevent some of dangers associated with climate change. 

In the analysis below, we will confirm the trends identified above by Keeling himself and use this data to fit a model to make a forecast of CO2 levels in the future.

## Exploratory Data Analysis
```{r load packages, echo = FALSE, message = FALSE, warning=FALSE, warn = FALSE}
library(tidyverse)
library(tsibble)
library(latex2exp)
library(magrittr)
library(patchwork)
library(lubridate)
library(feasts)
library(forecast)
library(zoo)
library(fable)
library(sandwich)
library(lmtest)
library(tseries)
library(gridExtra)
theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```

The data that we will analyze in this report is monthly data on the CO2 levels made at the Mauna Loa observatory from Jan 1959 to Dec 1997. According to the data documentation, the air at Mauna Loa is thought to be representative of much of the Northern Hemisphere and potentially the globe as well, as the observatory is at an altitude of 3400 meters and surrounded by bare lava, which allows for measurement of "background" air that is resistent to day-to-day fluctuations in CO2 levels. 

The data is in units of "mole fraction", which according to the data source is "defined as the number of carbon dioxide molecules in a given number of molecules of air, after removal of water vapor. For example, 413 parts per million of CO2 (abbreviated as ppm) means that in every million molecules of (dry) air there are on average 413 CO2 molecules." The data that makes up our dataset was measured daily from Jan 1959 to Dec 1997, but in our dataset appears as an averaged mean per month in ppm units.

Let's take a look at the data. In raw form, it appears as a matrix of doubles that represent the ppm measurements per month and year combination, as appears below. Let's create some initial EDA plots that will allow us to better understand the data. Let's start by analyzing time series, histogram, auto-correlation function (ACF), and partial auto-correlation function (PACF) plots.

```{r echo = FALSE, message = FALSE}
co2_df <- tsibble::as_tsibble(co2)
plot <- co2_df %>%
  ggplot + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Monthly Mean $CO_2$)'),
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )
hist <- co2_df %>%
  ggplot(aes(x=value)) + geom_histogram(bins=8) + labs(title="Histogram")
acf <- ggAcf(co2_df$value, lag.max=(15*12)) + labs(title="ACF")
pacf <- ggPacf(co2_df$value, lag.max=(15*12)) + labs(title="PACF")
plot + acf + hist + pacf + plot_layout(design = "
AAAAACCCC
AAAAACCCC
BBBBBCCCC
BBBBBCCCC
DDDDDCCCC
DDDDDCCCC
")
```
As we can see above, the data seems to follow a clear and increasing trend, with a distinct seasonal pattern that appears as "waves" that we would like to further analyze. The magnitude of the fluctuations do not appear to vary with the time series level, so in terms of decomposition, an additive model would likely fit this series best. The time series does not appear stationary from this plot, as the mean does not appear constant and in fact appears to increase over time, but the variance appears to be constant.

The ACF starts out close to 1 and declines slowly over time, losing significance but staying mostly positive and above the significance line until around lag 140. This slow decline in ACF is what we should see in a time series with a pronounced trend effect, and tracks with what we noticed in the previous time series plot. There appear to be "waves" in the ACF plot similar to the "waves" we also noticed in the time series plot, indicating that the there is a seasonal or cyclic component to our data. Thinking ahead to our modeling, the ACF seems to indicate an autoregressive component in our data generating process, as it declines slowly over time.

The PACF starts out with a single significant positive spike at lag 1, followed by a (relatively smaller) significant negative spike at lag 2, with oscillating clusters of positive and negative lags with much lower levels of significance as the lag number increases. Thinking ahead to our modeling, the PACF seems to indicate an moving average component in our data generating process, as it oscillates between positive and negative over time.

The histogram shows that the CO2 values seem to range between 300 and 380 ppm and do not appear normally distributed, with most values in between these two ranges. 

Let's take a closer look at the seasonality in the data. We'll start by creating a season plot and a subseries plot of the data.

```{r echo = FALSE, message = FALSE, fig.width=5, fig.height=8}
seasons <- ggseasonplot(x = co2, year.labels=TRUE, year.labels.left=TRUE) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Seasonal plot: Monthly mean $CO_2$)'))
subseries <- ggsubseriesplot(x = co2) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Subseries plot: Monthly mean $CO_2$)'))
seasons + subseries + plot_layout(design = "
AAAAAA
AAAAAA
AAAAAA
BBBBBB
")
```

From these plots, we can see that the CO2 levels appear to increase from January through May, then decrease from June through October, hitting a low in October, and then increase again from November through end of the year. The source report does mention that plants and soil absorbing and emitting CO2 could influence these measurements. A possible explanation could be that, in the colder months, we can expect higher CO2 levels as plants die off, and in the warmer months, we can expect lower CO2 levels as plants thrive. Of course, there is variability across the Northern Hemisphere in what counts as "colder" months and when plants thrive - for example, Hawaiian "winter" is temperate and plants can grow year round, so this could explain why the seasonal variability is slight across the year. We can again see the trend of CO2 levels increasing year by year, but the seasonality effect seems constant year after year without a noticeable increase in the magnitude of the fluctuations across years, again supporting an additive model.

We can confirm that our time series trend is increasing by removing our seasonality components and aggregating our data by year instead of month, as seen below.

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=3, fig.height=3}
year_agg_plot <- co2_df %>%
  mutate(year = year(index)) %>%
  index_by(year) %>%
  summarise(avg_value = sum(value)) %>%
  ggplot(aes(x = year, y = avg_value)) +
  geom_line() +
  labs(title = TeX(r'(Annual Mean $CO_2$ Levels)'), y = TeX(r'($CO_2$ Parts per Million)'), x = "Year") 
year_agg_plot
```

We can also use both additive and multiplicative decomposition to remove both the trend and seasonal movements from our dataset and confirm that the variance is stationary. The results from these decompositions are plotted below.

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=7, fig.height=5}
co2_df <- co2_df %>%
  mutate(log_value = log(value))
dcmp_add <- co2_df %>%
  model(stl = STL(value))
dcmp_multi <- co2_df %>%
 model(stl = STL(log_value))
decomp <- components(dcmp_add) %>% autoplot()
residuals <- components(dcmp_add)%>%
  ACF(remainder) %>%
  autoplot() + labs(title="Additive residuals")
log_decomp <- components(dcmp_multi) %>% autoplot()
log_residuals <- components(dcmp_multi) %>%
  ACF(remainder) %>%
  autoplot() + labs(title="Multiplicative residuals")
grid.arrange(decomp, residuals, log_decomp, log_residuals, nrow = 2, ncol = 2)
```

From these plots, we can confirm again that the time series is trending upwards, as seen in the "trend" sections of the decomposition plots. However, upon closer look, the fluctuations within the seasonality of the time series seem to grow slightly larger over time, which we can see in the "season_year" section of the top left plot. In the multiplicative plot on the bottom left, the "season_year" plot appears just slightly more stable, tentatively supporting the idea that this might actually be a multiplicative time series, contrary to our earlier findings. In the next section we should take a look at applying a log transform on our series prior to modeling.

Looking at the residual plots, the residuals on both appear stationary, meaning that the decomposition methods we are using was able to eliminate deterministic components from the time series. However, they do not appear to be white noise, meaning that there is still correlation in the data.

Let's complete our EDA by running statistical tests to determine whether our model is stationary or non-stationary. We will run both the Augmented Dickey-Fuller (ADF) test and the Phillips Perron (PP) test to do this, under the following hypotheses:

H0: Time series is non-stationary

H1: Time series is stationary

```{r echo = FALSE, message = FALSE, warning = FALSE}
adf.test(co2, alternative="stationary", k=5)
pp.test(co2)
```
Based on the ADF and PP tests, we can reject the null hypothesis that the time series is non-stationary. This is surprising as from our visual analysis of the time series plots, the time series does not appear to be stationary as the mean trends upwards. Because we know that both the ADF and PP tests have low power, we will move forward with the assumption that this time series is non-stationary based on our visual EDA.

## Modeling

Let's start by creating two linear models, one fit on our CO2 data and one fit on the log transform of our CO2 data. Since in our EDA we did notice that the fluctuations within the seasonality of the time series seem to grow slightly larger over time, potentially indicating a multiplicative series, we want to try out this log transform to see if it reduces variance in our model and leads to smaller residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_linear <- co2_df %>%
  model(trend_model = TSLM(value ~ trend()))
fit_linear_log <- co2_df %>%
  model(trend_model = TSLM(log_value ~ trend()))
fit_linear %>% report()
fit_linear_log %>% report()
```

We can see from the output here that the R-squared values on both models are high and the input coefficients are highly significant on both. We will also plot the models on top of our data.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_linear_plot <- augment(fit_linear)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Linear Model / Mean $CO_2$ Levels)')) 
fit_linear_log_plot <- augment(fit_linear_log)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Log Linear Model / Log Mean $CO_2$ Levels)')) 
grid.arrange(fit_linear_plot, fit_linear_log_plot, nrow = 1, ncol = 2)
```
From these plots, both models seem to do a similar job fitting the data but fail to account for any of the seasonal "waves". Next, let's examine the model residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_linear %>% gg_tsresiduals() + labs(title = "Linear Residuals") 
fit_linear_log %>% gg_tsresiduals() + labs(title = "Log Linear Residuals") 
```
The residuals don't look much different here between the linear and log linear models, signaling that a log transformation is unnecessary for the linear model. In both models, the ACFs show a periodic oscillating pattern which signals that something is missing from our model. Based on our EDA, this is most likely the seasonality that we discussed but did not account for in this model. Additionally, the residuals appear somewhat normally distributed for both models. Let's run a Ljung Box test to understand whether we have white noise residuals, under the following hypotheses:

H0: Data are independently distributed.

H1: Data are not independently distributed.

```{r echo = FALSE, message = FALSE, warning = FALSE}
linear_residuals <- fit_linear %>%
  augment() %>%
  select(.resid) %>%
  as.ts()
linear_log_residuals <- fit_linear_log %>%
  augment() %>%
  select(.resid) %>%
  as.ts()
Box.test(linear_residuals, lag = 1, type = "Ljung-Box")
Box.test(linear_residuals, lag = 10, type = "Ljung-Box")
Box.test(linear_log_residuals, lag = 1, type = "Ljung-Box")
Box.test(linear_log_residuals, lag = 10, type = "Ljung-Box")
```

Based on the Ljung Box test, we can reject the null that the data is independently distributed up to 10 lags, which means that we likely do not have white noise residuals and both our models are failing to account for some variance in our data (likely the seasonality).

Let's repeat this process with a quadratic trend model.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic <- co2_df %>%
   model(trend_model = TSLM(value ~ trend()+I(trend()^2))) 
 
fit_quadratic_log <- co2_df %>%
   model(trend_model = TSLM(log_value ~ trend()+I(trend()^2))) 
fit_quadratic %>% report()
fit_quadratic_log %>% report()
```

We can see from the output here that the R-squared values on both models are high and the input coefficients are highly significant on both. We will also plot the models on top of our data.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_plot <- augment(fit_quadratic)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Quadratic Model / Mean $CO_2$ Levels)')) 
fit_quadratic_log_plot <- augment(fit_quadratic_log)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Log Quadratic Model / Log Mean $CO_2$ Levels)')) 
grid.arrange(fit_quadratic_plot, fit_quadratic_log_plot, nrow = 1, ncol = 2)
```

From these plots, both models seem to do a similar job fitting the data. Next, let's examine the model residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic %>% gg_tsresiduals() + labs(title = "Quadratic Residuals") 
fit_quadratic_log %>% gg_tsresiduals() + labs(title = "Log Quadratic Residuals") 
```

The residuals don't look much different here between both models, signaling that a log transformation is unnecessary for the quadratic model as well. In both models, the ACFs show the same periodic oscillating pattern which signals that the seasonality is likely missing from our model. The residuals also appear somewhat normally distributed for both models. Let's run a Ljung Box test again to understand whether we have white noise residuals under the same hypotheses as before:

```{r echo = FALSE, message = FALSE, warning = FALSE}
quadratic_residuals <- fit_quadratic %>%
  augment() %>%
  select(.resid) %>%
  as.ts()
quadratic_log_residuals <- fit_quadratic_log %>%
  augment() %>%
  select(.resid) %>%
  as.ts()
Box.test(quadratic_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_residuals, lag = 10, type = "Ljung-Box")
Box.test(quadratic_log_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_log_residuals, lag = 10, type = "Ljung-Box")
```

As before, based on the Ljung Box test, we can reject the null that the data is independently distributed up to 10 lags, which means that we likely do not have white noise residuals and both our models are failing to account for some variance in our data (likely again the seasonality).

Since the log transforms don't appear to reduce any of the variance in our models, I am going to compare the linear model directly with the quadratic model on non-transformed data. Our previous analysis shows that both models are behaving similarly but the quadratic model did have smaller residuals compared to the linear model, making it the more favorable model. In addition to the residual analysis, I going to compare the two using the Bayesian Information Criteria (BIC) as my metric.

```{r echo = FALSE, message = FALSE, warning = FALSE}
glance(fit_linear) %>% 
  select(BIC)
glance(fit_quadratic) %>% 
  select(BIC)
```

The quadratic model has a lower BIC, so I will move forward using the quadratic model. Our next step is to fit a polynomial model that incorporates seasonal dummy variables, which will hopefully account for some of the variance that we failed to capture in our previous models. We'll create models using both the log transform and the normal CO2 values, although it has appeared from our past models that the log transform does not seem to account for much, if any, variance in our data.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_season <- co2_df %>%
  model(trend_model = TSLM(value ~ trend() + I(trend()^2) + season())) 
fit_quadratic_log_season <- co2_df %>%
  model(trend_model = TSLM(log_value ~ trend() + I(trend()^2) + season())) 
fit_quadratic_season %>% report()
fit_quadratic_log_season %>% report()
```

Just from this summary, we can see that the R-squared values are slightly higher on both of these seasonal models than either the linear or quadratic models. We can also see that all the input coefficients are highly significant. Let's plot our models next.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_season_plot <- augment(fit_quadratic_season)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Quadratic Seasonal Model / Mean $CO_2$ Levels)')) 
fit_quadratic_log_season_plot <- augment(fit_quadratic_log_season)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Log Quadratic Seasonal Model / Log Mean $CO_2$ Levels)')) 
grid.arrange(fit_quadratic_season_plot, fit_quadratic_log_season_plot, nrow = 1, ncol = 2)
```

From these plots, both models seem to do a similar job fitting the data and, unlike the previous models we've seen, actually account for the seasonal "waves" in our plot and track them pretty closely. Next, let's examine the model residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_season %>% gg_tsresiduals() + labs(title = "Quadratic Season Residuals") 
fit_quadratic_log_season %>% gg_tsresiduals() + labs(title = "Log Quadratic Season Residuals") 
```

The residuals again don't look much different here between both models, signaling that a log transformation is unnecessary for this seasonal quadratic model as well. In both models, the ACFs now shows highly significant and slowly declining lags, unlike the ACF plots on the previous models which showed an oscillating trend that was likely related to seasonality variance that our latest models are now capturing. The residuals appear somewhat normally distributed for both models. In comparison to both the non-seasonal linear and quadratic models, the residuals are small in magnitude. Let's run a Ljung Box test again to understand whether we have white noise residuals under the same hypotheses as before:

```{r echo = FALSE, message = FALSE, warning = FALSE}
quadratic_season_residuals <- fit_quadratic_season %>%
  augment() %>%
  select(.resid) %>%
  as.ts()
quadratic_log_season_residuals <- fit_quadratic_log_season %>%
  augment() %>%
  select(.resid) %>%
  as.ts()
Box.test(quadratic_season_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_season_residuals, lag = 10, type = "Ljung-Box")
Box.test(quadratic_log_season_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_log_season_residuals, lag = 10, type = "Ljung-Box")
```

As before, based on the Ljung Box test, we can reject the null that the data is independently distributed up to 10 lags, which means that we likely do not have white noise residuals and both our models are failing to account for some variance in our data. This is surprising as our residuals are quite small, especially in comparison to our previous models. Let's compare the BIC of the quadratic seasonal model without the log transform to our previous BICs.

Let's compare the BIC of this model against the pure linear and quadratic models without seasonal components.

```{r echo = FALSE, message = FALSE, warning = FALSE}
glance(fit_quadratic_season) %>% 
  select(BIC)
```

The BIC for our quadratic seasonal model is much smaller than the BICs for either our linear or quadratic model, and by this criteria is our best model that we have fit so far. Let's use this model to generate forecasts to the year 2020.

```{r echo = FALSE, message = FALSE, warning = FALSE}
future_df <- new_data(co2_df, n=23 * 12)
predictions <- fit_quadratic_season %>%
  forecast(new_data = future_df)
fit_quadratic_season %>%
  forecast(new_data = future_df) %>%
  autoplot(co2_df) + labs(title = "CO2 Predictions Using Seasonal Quadratic Model")
```

We can see that these predictions continue to follow the trend and seasonal fluctuations that we noticed in our data. Let's complete our linear modeling by examining the CLM assumptions for our best model, the seasonal quadratic model.

The first CLM assumption is that the underlying data generating process follows a linear model. We cannot check this assumption and will just assume it's true, or that we are just fitting the best linear model to the data if it is untrue.

The second assumption is ergodatic stationarity. Since this model is including trend and seasonal variables, we are eliminating the deterministic parts in the process and are satisfying this assumption. From the ACF plot, the process does look stationary but the residuals do appear serially correlated.

The third assumption is no perfect multicollinearity. When we fit our model, R did not report any warning or missing coefficients, which means that this assumption is violated.

The fourth assumption is the zero conditional mean assumption. We can evaluate this by looking at these residuals versus the fitted value plot, which appears below. If this assumption is satisfied, there should be no relationship between the fitted values and the residuals, a.k.a. there should be a straight line in the plot.

```{r echo = FALSE, message = FALSE, warning = FALSE}
augment(fit_quadratic_season) %>%
  ggplot(aes(x = .fitted, y = .innov)) +
  geom_point() +
  geom_smooth(se=FALSE)+
  scale_x_log10() +
  labs(title = "Seasonal Quadratic Model Residuals vs Fitted")
```

The line is curved, so we cannot justify that the zero conditional mean assumption is satisfied, meaning that there are likely additional variables that should be included in our model.

The fifth CLM assumption is homoskedasticity. The residuals are quite spread out with a large range of variance, so it seems as though this assumption cannot be satisfied.

The last assumption is no serial correlation. From our ACF plot, the residuals do appear to be serially correlated. Additionally, the Ljung Box test returns a high statistic with a small p-value. We can reject the null hypothesis that there is no autocorrelation and conclude that our residuals here are autocorrelated, thereby not satisfying this assumption.

The residuals do look close to a normal distribution, which gives us more confidence in our generated prediction intervals.

###ARIMA Modeling

Now, let's choose an ARIMA model to fit to the CO2 data. Recall that our EDA indicated that the CO2 data had the following characteristics: * non-stationary data series, 
* slowly decaying ACF plot, indicative of an AR process
* oscillating PCAF plot, indicative of an MA process
* seasonal data

In order to transform the data into a stationary series, we can start by applying a first-order difference to the series. 

```{r}

#first-order difference
first_diff <- co2_df %>%
  mutate(diff_co2 = difference(value)) 

co2_df %>%
gg_tsdisplay(difference(value),
               plot_type='partial', lag=36) +
  labs(title="First-order differenced", y="")
```
Based on the trend plot, the data seems to stabilize around a mean of -0.5, and it appears to have a constant variance, suggesting that the data only needs a first-order difference. The ACF plot continues to decay gradually but the oscillating behavior persists here. This indicates that the seasonal pattern is strong and stable after a first-order difference. As a result, we will want to use a seasonal difference in addition to this first difference. Since the seasonal behavior repeats every year, we will set m = 12, meaning the seasonal pattern repeats once every twelve months.

```{r}
#seasonally differenced
co2_s_diff <- co2_df %>%
  mutate(sdiff_co2 = difference(value, 12)) 

co2_s_diff

#plots for seasonal differencing
co2_df  %>%
gg_tsdisplay(difference(value, 12),
               plot_type='partial', lag=36) +
  labs(title="Seasonally differenced", y="")

```

On its own, seasonal differencing does not appear to make the data stationary. However, based on the ACF plot, we can confirm that the seasonal differencing either removes or significantly reduces the oscillation as it does not seem apparent anymore. As a result, we can conclude that we need both a first difference and a seasonal difference on the series. We can confirm these observations using the following unit root tests. We will first use the  Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test under the following hypothesis:

H0: The data are stationary
HA: The data are not stationary

```{r}
#unit root tests

co2_df %>%
  features(value, unitroot_kpss)

first_diff %>%
  features(diff_co2, unitroot_kpss)

co2_s_diff %>%
  features(sdiff_co2, unitroot_kpss )

```

We can interpret the tests in the following manner:
* For the undifferenced data, the test statistic (7.81) is bigger than the 1% critical value, so the p-value is less than 0.01, indicating that the null hypothesis is rejected. That is, the data are not stationary.
* For the first differenced data, the p-value is greater than 0.1, indicating the test fails to reject the null hypothesis. That is, the data are stationary.
* For the seasonally differenced data, the test statistic (1.94) is bigger than the 1% critical value, so the p-value is less than 0.01, indicating that the null hypothesis is rejected. That is, the data are not stationary.
Thus, we can conclude that we need both a first difference and a seasonal difference. But, how many differences do we need? To confirm that we are applying the appropriate amount of differences, we can use the following:

```{r}

#confirm the number of differences needed in the data
co2_df %>%
  features(value, unitroot_ndiffs)

first_diff %>%
  features(diff_co2, unitroot_ndiffs)

co2_s_diff %>%
  features(sdiff_co2, unitroot_ndiffs)

#test need for seasonal differencing; indicating one seasonal difference is required

co2_df %>%
  features(value, unitroot_nsdiffs)

first_diff %>%
  features(diff_co2, unitroot_nsdiffs)

co2_s_diff %>%
  features(sdiff_co2, unitroot_nsdiffs)
```

Here we can see that once we apply a first difference and a seasonal difference, the test returns 0, indicating no additional differences are required. It is important that we correctly identify the correct number of differences as we could potentially introduce false dynamics or autocorrelations into the time series.

```{r}
#double differenced
co2_df %>%
  gg_tsdisplay(difference(value, 12) %>% difference(),
               plot_type='partial', lag=36) +
  labs(title = "Double differenced", y="")
```
We will now use the ACF and PACF plots of our double differenced data to determine an appropriate ARIMA model via brute force. The significant spike at lag 3 in the ACF suggests a non-seasonal MA(3) component. The significant spike at lag 12 in the ACF suggests a seasonal MA(1) component. So, we might begin with an ARIMA(0,1,3)(0,1,1)12 model, indicating a first difference, a seasonal difference, and non-seasonal MA(3) and seasonal MA(1) component. 

```{r}
fit1 <- arima(co2_df$value, order = c(0,1,3), seasonal= list(order = c(0,1,1), period = 12))
fit1
```

```{r}
resid <- residuals(fit1)
autoplot(resid)
ggAcf(resid)

Box.test(resid,lag=10, fitdf=0, type="Lj")
```
The ACF plot indicates that the residuals are following a white noise process as each autocorrelation is close to zero and 95% of spikes lie within significance thresholds. There is one small but significant spike at lag 8. Additionally, since the p-value from the Box-Ljung test is greater than 0.05, we fail to reject the null hypothesis and conclude that there is no serial correlation in the data.

If we had evaluated the PACF as well, we may have chosen ARIMA(3,1,0)(1,1,1)12 model, indicating a first difference, a seasonal difference, non-seasonal AR(3) and MA(1) components, and seasonal AR(1) and AR(1) component. The significant spike at lag 3 in the PACF suggests a non-seasonal AR(3) component. The significant spike at lag 12 in the PACF suggests a seasonal AR(1) component. However, by comparing the AIC values of the first and second model, the first selection was a better fit based on the lower AIC value.

```{r}
fit2 <- arima(co2_df$value, order = c(3,1,1), seasonal= list(order = c(1,1,1), period = 12))
fit2
```

We can also try automatically fitting the model with the following code:
```{r}
#documentation seems outdated
#source_1:https://otexts.com/fpp2/seasonal-arima.html
#source_2:https://campus.datacamp.com/courses/forecasting-in-r/forecasting-with-arima-models?ex=10

auto_fit <- co2_df %>% model(ARIMA(value)) %>%  report()

```


```{r}
auto_fit %>% 
  gg_tsresiduals(lag=36) 


auto_resid <- residuals(auto_fit)
auto_resid
Box.test(auto_resid[3] ,lag=10, fitdf=0, type="Lj")

```
The trend and ACF plots indicate that the residuals of the automatically fitted ARIMA model are following a white noise process. Autocorrelations are close to zero and 95% of spikes lie within significance thresholds. There is one small but significant spike at lag 9. Also, since the p-value from the Box-Ljung test is greater than 0.05, we fail to reject the null hypothesis and conclude that there is no serial correlation in the data. However, the automatically fitted ARIMA model does not outperform our first guess as the AIC in `r auto_fit` is higher. We will continue to proceed with the ARIMA(0,1,3)(0,1,1)12.

```{r}
future_d <- new_data(co2_df, n=25 * 12)

co2_df %>%
  model(ARIMA(value ~ 0 + pdq(0,1,3) + PDQ(0,1,1))) %>%
  forecast(new_data = future_d) %>%
  autoplot(co2_df ) +
  labs(x = 'Month of Year',
    y="CO2 (PPM)",
       title="CO2 measurements over time")

```

Again, we can see that these predictions continue to follow the trend and seasonal fluctuations that we noticed earlier in the data. However, our confidence intervals continue to widen with each year that we forecast. 

###Forecast atmospheric CO2 growth

If we generate predictions for when atmospheric CO2 is expected to be at 420 ppm and 500 ppm levels at the 95% confidence level, we can observe the wide confidence intervals noted in the previous graph. Predictions for 420ppm were as early as April 2022 and as late as December 2100. Surprisingly, when we make predictions on for 500ppm the confidence intervals narrow. According to this model's predictions, 500ppm CO2 levels will occur as early as March 2055 and as late as August 2086.

```{r}
co2_ext_forecast <- forecast(fit1, h=103 * 12, level = c(95))
co2_ext_forecast <- summary(co2_ext_forecast)

ts.d  <- as.data.frame(as.yearmon(1998 + seq(0, 1235)/12))

forecast_df <- cbind(ts.d, co2_ext_forecast)
colnames(forecast_df )[1] <- "time_index"
colnames(forecast_df )[2] <- "point_forecast"
colnames(forecast_df )[3] <- "lo_95"
colnames(forecast_df )[4] <- "high_95"

forecast420ppm <- forecast_df %>%
 filter(round(point_forecast,0) == 420 | round(lo_95,0) == 420 | round(high_95,0) == 420)

min(forecast420ppm$time_index) 
max(forecast420ppm$time_index)

max(forecast420ppm$time_index) - min(forecast420ppm$time_index) 

forecast500ppm <-forecast_df %>%
 filter(round(point_forecast,0) == 500 | round(lo_95,0) == 500 | round(high_95,0) == 500)

min(forecast500ppm$time_index) 
max(forecast500ppm$time_index)

max(forecast500ppm$time_index) - min(forecast500ppm$time_index) 

forecast500ppm <-forecast_df %>%
 filter(round(point_forecast,0) == 500 | round(lo_95,0) == 500 | round(high_95,0) == 500)
```

When we look specifically at CO2 levels in 2100, we can expect the ppm values to be around 525 throughout the course of the year with fairly wide confidence intervals about 100ppms lower or higher. Given that the NOAA reported that the Earth reached 419ppm back in May 2021, it would appear that the accuracy of the model is off for a closer 

```{r}
sapply(forecast_df, class)

forecast_df %>%
 filter(year(time_index)==2100)

forecast_df %>%
 filter(year(time_index)==2100)%>%
  ggplot(aes(time_index, point_forecast)) + geom_point() + 
  geom_errorbar(aes(ymin = lo_95, ymax = high_95)) +
  labs(x = 'Month of Year',
    y="CO2 (PPM)",
       title="2100 CO2 predictions")
```
Based on the very wide confidence intervals, we're not very confident that these are accurate predictions. To assess the accuracy of our predictions compared to another model, we can also look at the root mean squared error (RMSE). We'll use an ETS model as our point of comparison for RMSE. We should expect that the ETS model should perform worse as it does not perform as well with larger seasonal frequency.

```{r}
#https://robjhyndman.com/hyndsight/longseasonality/

train <- co2_df %>% filter_index(. ~ "1989 Jan")

fit_arima <- train %>% model(ARIMA(value))
report(fit_arima)

fit_arima %>% gg_tsresiduals(lag_max = 16)

augment(fit_arima) %>%
  features(.innov, ljung_box, lag = 16, dof = 6)

fit_ets <- train %>% model(ETS(value))
report(fit_ets)

fit_ets %>%
  gg_tsresiduals(lag_max = 16)

augment(fit_ets) %>%
  features(.innov, ljung_box, lag = 16, dof = 6)

bind_rows(
    fit_arima %>% accuracy(),
    fit_ets %>% accuracy(),
    fit_arima %>% forecast(h = 10) %>% accuracy( co2_df),
    fit_ets %>% forecast(h = 10) %>% accuracy( co2_df)
  )


```

Based on the above results, the ARIMA and ETS models perform about the same based on the RMSE values on the test sets. While our predictions are probably a best guess given the information that we have, the ARIMA model assumes that seasonality is fixed over time, and this is a strong assumption to make given that there are other factors that could likely impact CO2 over time.


