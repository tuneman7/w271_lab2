---
title: "Atmospheric CO2 Comprehensive Analysis"
author: "Aastha Khana, Eda Kavlakoglu, Don Irwin, Ben Mok"
date: "07/13/2022"
output:
  pdf_document:
    toc: yes
    number_sections: yes
    pandoc_args: --listings
    includes:
      in_header: preamble.tex
  html_document: default
  word_document:
    toc: yes
subtitle: U.C. Berkeley, MIDS, Summer 2022, W271 Lab2
geometry: left=1cm,right=1cm,top=1cm,bottom=1.5cm
---

# Report from the Point of View of 1997 

## Introduction

In the 1950s, a geochemist, Charles David Keeling, began to collect air samples to measure the amount of carbon dioxide in the air, and these measurements would become his life's work. His initial samples indicated that the air contained more CO2 at night compared to the daytime. This finding suggested that plants absorbed CO2 during the day and released CO2 during the evening. Over time, his measurements showed a seasonal cycle, which was consistent with the seasonal patterns of terrestrial vegetation, and the CO2 data also would persistently increase over time. This rise in CO2 prompted questions about preconceived notions around the ocean's ability to absorb CO2 emitted by fossil fuels. If CO2 released by coal, natural gas, and petroleum remained in the air, this could account for the rise in CO2 over the years. 

This finding is incredibly important, because the rising rate of CO2 has implications on the Earth's ability to release heat from the atmosphere. If heat isn't able to escape, then this would subsequently result in a warmer climate, which would become known as the "greenhouse effect". However, while the CO2 data demonstrated a clear upward trend over time, it was also marked by periods of decline which could not solely be attributed to plant growth seasonality. A deeper investigation revealed that El Nino weather patterns affected the amount of CO2 that was released in the air by vegetation and soils. Over time, the data would also show earlier seasonal starts, and when this data was layered with temperature data, it had become clear that the concerns of a warming planet years earlier were starting to manifest itself within the data. Since this connection has been established between rising CO2 and corresponding global temperatures, more attention has surrounded the topics of global warming and climate change. As a result, business and political decision makers are starting to incorporate this data into their longer-term strategies; however, their pace of action may be too slow to prevent some of dangers associated with climate change. 

In the analysis below, we will confirm the trends identified above by Keeling himself and use this data to fit a model to make a forecast of CO2 levels in the future.

## Exploratory Data Analysis
```{r load packages 1997, echo = FALSE, message = FALSE, warning=FALSE, warn = FALSE}
library(tidyverse)
library(tsibble)
library(latex2exp)
library(magrittr)
library(patchwork)
library(lubridate)
library(feasts)
library(forecast)
library(zoo)
library(fable)
library(sandwich)
library(lmtest)
library(tseries)
library(gridExtra)

theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```

The data that we will analyze in this report is monthly data on the CO2 levels made at the Mauna Loa observatory from Jan 1959 to Dec 1997. According to the data documentation, the air at Mauna Loa is thought to be representative of much of the Northern Hemisphere and potentially the globe as well, as the observatory is at an altitude of 3400 meters and surrounded by bare lava, which allows for measurement of "background" air that is resistent to day-to-day fluctuations in CO2 levels. 

The data is in units of "mole fraction", which according to the data source is "defined as the number of carbon dioxide molecules in a given number of molecules of air, after removal of water vapor. For example, 413 parts per million of CO2 (abbreviated as ppm) means that in every million molecules of (dry) air there are on average 413 CO2 molecules." The data that makes up our dataset was measured daily from Jan 1959 to Dec 1997, but in our dataset appears as an averaged mean per month in ppm units.

In raw form, the data appears as a matrix of doubles that represent the ppm measurements per month and year combination. Let's create some initial EDA plots that will allow us to better understand the data, starting by analyzing the time series, histogram, auto-correlation function (ACF), and partial auto-correlation function (PACF) plots.

### Standard time series graph analysis

```{r echo = FALSE, message = FALSE}
co2_df <- tsibble::as_tsibble(co2)

plot <- co2_df %>%
  ggplot + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Monthly Mean $CO_2$)'),
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )
hist <- co2_df %>%
  ggplot(aes(x=value)) + geom_histogram(bins=8) + labs(title="Histogram")
acf <- ggAcf(co2_df$value, lag.max=(15*12)) + labs(title="ACF")
pacf <- ggPacf(co2_df$value, lag.max=(15*12)) + labs(title="PACF")

plot + acf + hist + pacf + plot_layout(design = "
AAAAACCCC
AAAAACCCC
BBBBBCCCC
BBBBBCCCC
DDDDDCCCC
DDDDDCCCC
")
```

As we can see above, the data seems to follow a clear and increasing trend, with a distinct seasonal pattern that appears as "waves" that we would like to further analyze. The magnitude of the fluctuations do not appear to vary with the time series level, so in terms of decomposition, an additive model would likely fit this series best. The time series does not appear stationary from this plot, as the mean does not appear constant and in fact appears to increase over time, but the variance appears to be constant.

The ACF starts out close to 1 and declines slowly over time, losing significance but staying mostly positive and above the significance line until around lag 140. This slow decline in ACF is what we should see in a time series with a pronounced trend effect, and tracks with what we noticed in the previous time series plot. There appear to be "waves" in the ACF plot similar to the "waves" we also noticed in the time series plot, indicating that the there is a seasonal or cyclic component to our data. Thinking ahead to our modeling, the ACF seems to indicate an autoregressive component in our data generating process, as it declines slowly over time.

The PACF starts out with a single significant positive spike at lag 1, followed by a (relatively smaller) significant negative spike at lag 2, with oscillating clusters of positive and negative lags with much lower levels of significance as the lag number increases. Thinking ahead to our modeling, the PACF seems to indicate an moving average component in our data generating process, as it oscillates between positive and negative over time.

The histogram shows that the CO2 values seem to range between 300 and 380 ppm and do not appear normally distributed, with most values in between these two ranges. 

### Analyzing seasonality

Let's take a closer look at the seasonality in the data. We'll start by creating a season plot and a subseries plot of the data.

```{r echo = FALSE, message = FALSE, fig.width=5, fig.height=6}
seasons <- ggseasonplot(x = co2, year.labels=TRUE, year.labels.left=TRUE) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Seasonal plot: Monthly mean $CO_2$)'))

subseries <- ggsubseriesplot(x = co2) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Subseries plot: Monthly mean $CO_2$)'))

seasons 
```

```{r echo = FALSE, message = FALSE, fig.width=5, fig.height=2}
subseries
```

From these plots, we can see that the CO2 levels appear to increase from January through May, then decrease from June through October, hitting a low in October, and then increase again from November through end of the year. The source report does mention that plants and soil absorbing and emitting CO2 could influence these measurements. A possible explanation could be that, in the colder months, we can expect higher CO2 levels as plants die off, and in the warmer months, we can expect lower CO2 levels as plants thrive. Of course, there is variability across the Northern Hemisphere in what counts as "colder" months and when plants thrive - for example, Hawaiian "winter" is temperate and plants can grow year round, so this could explain why the seasonal variability is slight across the year. We can again see the trend of CO2 levels increasing year by year, but the seasonality effect seems constant year after year without a noticeable increase in the magnitude of the fluctuations across years, again supporting an additive model.

We can confirm that our time series trend is increasing by removing our seasonality components and aggregating our data by year instead of month, as seen below.

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=3, fig.height=3}
year_agg_plot <- co2_df %>%
  mutate(year = year(index)) %>%
  index_by(year) %>%
  summarise(avg_value = sum(value)) %>%
  ggplot(aes(x = year, y = avg_value)) +
  geom_line() +
  labs(title = TeX(r'(Annual Mean $CO_2$ Levels)'), y = TeX(r'($CO_2$ Parts per Million)'), x = "Year") 

year_agg_plot
```
\newpage

### Removing trend and seasonal movements

We can also use both additive and multiplicative decomposition to remove both the trend and seasonal movements from our dataset and confirm that the variance is stationary. The results from these decompositions are plotted below.

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=7, fig.height=4}
co2_df <- co2_df %>%
  mutate(log_value = log(value))

dcmp_add <- co2_df %>%
  model(stl = STL(value))

dcmp_multi <- co2_df %>%
 model(stl = STL(log_value))

decomp <- components(dcmp_add) %>% autoplot()
residuals <- components(dcmp_add)%>%
  ACF(remainder) %>%
  autoplot() + labs(title="Additive residuals")
log_decomp <- components(dcmp_multi) %>% autoplot()
log_residuals <- components(dcmp_multi) %>%
  ACF(remainder) %>%
  autoplot() + labs(title="Multiplicative residuals")

grid.arrange(decomp, residuals, log_decomp, log_residuals, nrow = 2, ncol = 2)
```

From these plots, we can confirm again that the time series is trending upwards, as seen in the "trend" sections of the decomposition plots. However, upon closer look, the fluctuations within the seasonality of the time series seem to grow slightly larger over time, which we can see in the "season_year" section of the top left plot. In the multiplicative plot on the bottom left, the "season_year" plot appears just slightly more stable, tentatively supporting the idea that this might actually be a multiplicative time series, contrary to our earlier findings. In the next section we should look at applying a log transform on our series prior to modeling.

Looking at the residual plots, the residuals on both appear stationary, meaning that the decomposition methods we are using was able to eliminate deterministic components from the time series. However, they do not appear to be white noise, meaning that there is still correlation in the data.

### Testing whether time series is stationary

Let's complete our EDA by running statistical tests to determine whether our model is stationary or non-stationary. We will run both the Augmented Dickey-Fuller (ADF) test and the Phillips Perron (PP) test to do this, under the following hypotheses:

H0: Time series is non-stationary

H1: Time series is stationary

```{r echo = FALSE, message = FALSE, warning = FALSE}
adf.test(co2, alternative="stationary", k=5)
pp.test(co2)
```

Based on the ADF and PP tests, we can reject the null hypothesis that the time series is non-stationary. This is surprising as based on our visual analysis of the time series plots, the time series does not appear to be stationary with a mean that trends upwards. Because we know that both the ADF and PP tests have low power, we will move forward with the assumption that this time series is non-stationary based on our visual EDA.

## Modeling

### Linear and log-linear models

Let's start by creating two linear models, one fit on our CO2 data and one fit on the log transform of our CO2 data. Since in our EDA we did notice that the fluctuations within the seasonality of the time series seem to grow slightly larger over time, potentially indicating a multiplicative series, we want to try out this log transform to see if it reduces variance in our model and leads to smaller residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_linear <- co2_df %>%
  model(trend_model = TSLM(value ~ trend()))

fit_linear_log <- co2_df %>%
  model(trend_model = TSLM(log_value ~ trend()))

fit_linear %>% report()
fit_linear_log %>% report()
```

We can see from the output here that the R-squared values on both models are high and the input coefficients are highly significant on both. We will also plot the models on top of our data.

```{r echo = FALSE, message = FALSE, warning = FALSE,fig.width=8, fig.height=4}
fit_linear_plot <- augment(fit_linear)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Linear Model / Mean $CO_2$ Levels)')) 

fit_linear_log_plot <- augment(fit_linear_log)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Log Linear Model / Log Mean $CO_2$ Levels)')) 

grid.arrange(fit_linear_plot, fit_linear_log_plot, nrow = 1, ncol = 2)
```
From these plots, both models seem to do a similar job fitting the data but fail to account for any of the seasonal "waves". Next, let's examine the model residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_linear %>% gg_tsresiduals() + labs(title = "Linear Residuals") 
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_linear_log %>% gg_tsresiduals() + labs(title = "Log Linear Residuals") 
```

The residuals don't look much different here between the linear and log linear models, signaling that a log transformation is unnecessary for the linear model. In both models, the ACFs show a periodic oscillating pattern which signals that something is missing from our model. Based on our EDA, this is most likely the seasonality that we discussed but did not account for in this model. Additionally, the residuals appear somewhat normally distributed for both models. Let's run a Ljung Box test to understand whether we have white noise residuals, under the following hypotheses:

H0: Data are independently distributed.

H1: Data are not independently distributed.

```{r echo = FALSE, message = FALSE, warning = FALSE}
linear_residuals <- fit_linear %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

linear_log_residuals <- fit_linear_log %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

Box.test(linear_residuals, lag = 1, type = "Ljung-Box")
Box.test(linear_residuals, lag = 10, type = "Ljung-Box")
Box.test(linear_log_residuals, lag = 1, type = "Ljung-Box")
Box.test(linear_log_residuals, lag = 10, type = "Ljung-Box")
```

Based on the Ljung Box test, we can reject the null that the data is independently distributed up to 10 lags, which means that we likely do not have white noise residuals and both our models are failing to account for some variance in our data (likely the seasonality).

### Explaining variance with quadradic trend models

Let's repeat this process with a quadratic trend model to see if this model accounts for additional variance in our process.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic <- co2_df %>%
   model(trend_model = TSLM(value ~ trend()+I(trend()^2))) 
 
fit_quadratic_log <- co2_df %>%
   model(trend_model = TSLM(log_value ~ trend()+I(trend()^2))) 

fit_quadratic %>% report()
fit_quadratic_log %>% report()
```

We can see from the output here that the R-squared values on both models are high and the input coefficients are highly significant on both. We will also plot the models on top of our data.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_plot <- augment(fit_quadratic)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Quadratic Model / Mean $CO_2$ Levels)')) 

fit_quadratic_log_plot <- augment(fit_quadratic_log)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Log Quadratic Model / Log Mean $CO_2$ Levels)')) 

grid.arrange(fit_quadratic_plot, fit_quadratic_log_plot, nrow = 2, ncol = 1)
```

From these plots, both models seem to do a similar job fitting the data. Next, let's examine the model residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic %>% gg_tsresiduals() + labs(title = "Quadratic Residuals") 
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_log %>% gg_tsresiduals() + labs(title = "Log Quadratic Residuals") 
```

The residuals don't look much different here between both models, signaling that a log transformation is unnecessary for the quadratic model as well. In both models, the ACFs show the same periodic oscillating pattern which signals that the seasonality is likely missing from our model. The residuals also appear somewhat normally distributed for both models. Let's run a Ljung Box test again to understand whether we have white noise residuals under the same hypotheses as before.

```{r echo = FALSE, message = FALSE, warning = FALSE}
quadratic_residuals <- fit_quadratic %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

quadratic_log_residuals <- fit_quadratic_log %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

Box.test(quadratic_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_residuals, lag = 10, type = "Ljung-Box")
Box.test(quadratic_log_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_log_residuals, lag = 10, type = "Ljung-Box")
```

As before, based on the Ljung Box test, we can reject the null that the data is independently distributed up to 10 lags, which means that we likely do not have white noise residuals and both our models are failing to account for some variance in our data (likely again the seasonality).

Since the log transforms don't appear to reduce any of the variance in our models, I am going to compare the linear model directly with the quadratic model on non-transformed data. Our previous analysis shows that both models are behaving similarly but the quadratic model has smaller residuals compared to the linear model, making it our more favorable model. In addition to the residual analysis, I going to compare the two using the Bayesian Information Criteria (BIC) as my metric.

```{r echo = FALSE, message = FALSE, warning = FALSE}
glance(fit_linear) %>% 
  select(BIC)

glance(fit_quadratic) %>% 
  select(BIC)
```

The quadratic model has a lower BIC, so I will move forward with our modeling process using this quadratic model. Our next step is to fit a polynomial model that incorporates seasonal dummy variables, which will hopefully account for some of the variance that we failed to capture in our previous models. We'll create models using both the log transform and the normal CO2 values, although it has appeared from our past models that the log transform does not seem to account for much, if any, variance in our data.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_season <- co2_df %>%
  model(trend_model = TSLM(value ~ trend() + I(trend()^2) + season())) 

fit_quadratic_log_season <- co2_df %>%
  model(trend_model = TSLM(log_value ~ trend() + I(trend()^2) + season())) 

fit_quadratic_season %>% report()
fit_quadratic_log_season %>% report()
```

Just from this summary, we can see that the R-squared values are slightly higher on both of these seasonal models than either the linear or quadratic models. We can also see that all the input coefficients are highly significant. Let's plot our models next.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_season_plot <- augment(fit_quadratic_season)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Quadratic Seasonal Model / Mean $CO_2$ Levels)')) 

fit_quadratic_log_season_plot <- augment(fit_quadratic_log_season)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Log Quadratic Seasonal Model / Log Mean $CO_2$ Levels)')) 

grid.arrange(fit_quadratic_season_plot, fit_quadratic_log_season_plot, nrow = 2, ncol = 1)
```

From these plots, both models seem to do a similar job fitting the data and, unlike the previous models we've seen, actually account for the seasonal "waves" in our plot and track them pretty closely. Next, let's examine the model residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_season %>% gg_tsresiduals() + labs(title = "Quadratic Season Residuals") 
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_log_season %>% gg_tsresiduals() + labs(title = "Log Quadratic Season Residuals") 
```

The residuals again don't look much different here between both models, signaling that a log transformation is unnecessary for this seasonal quadratic model as well. In both models, the ACFs now shows highly significant and slowly declining lags, unlike the ACF plots on the previous models which showed an oscillating trend that was likely related to seasonality variance that our latest models are now capturing. The residuals appear somewhat normally distributed for both models. In comparison to both the non-seasonal linear and quadratic models, the residuals are small in magnitude. Let's run a Ljung Box test again to understand whether we have white noise residuals under the same hypotheses as before:

```{r echo = FALSE, message = FALSE, warning = FALSE}
quadratic_season_residuals <- fit_quadratic_season %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

quadratic_log_season_residuals <- fit_quadratic_log_season %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

Box.test(quadratic_season_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_season_residuals, lag = 10, type = "Ljung-Box")
Box.test(quadratic_log_season_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_log_season_residuals, lag = 10, type = "Ljung-Box")
```

As before, based on the Ljung Box test, we can reject the null that the data is independently distributed up to 10 lags, which means that we likely do not have white noise residuals and both our models are failing to account for some variance in our data. This is somewhat surprising as our residuals are quite small, especially in comparison to our previous models. Let's compare the BIC of the quadratic seasonal model without the log transform to our previous BICs.

### Model selection

Let's compare the BIC of this model against the pure linear and quadratic models without seasonal components.

```{r echo = FALSE, message = FALSE, warning = FALSE}
glance(fit_quadratic_season) %>% 
  select(BIC)
```

The BIC for our quadratic seasonal model is much smaller than the BICs for either our linear or quadratic model, and by this criteria is our best model that we have fit so far. Let's use this model to generate forecasts to the year 2020.

### Forecasts based on models

```{r echo = FALSE, message = FALSE, warning = FALSE}
future_df <- new_data(co2_df, n=23 * 12)

predictions <- fit_quadratic_season %>%
  forecast(new_data = future_df)

fit_quadratic_season %>%
  forecast(new_data = future_df) %>%
  autoplot(co2_df) + labs(title = "CO2 Predictions Using Seasonal Quadratic Model")
```

We can see that these predictions continue to follow the trend and seasonal fluctuations that we noticed in our data. Let's complete our linear modeling by examining the CLM assumptions for our best model, the seasonal quadratic model.

The first CLM assumption is that the underlying data generating process follows a linear model. We cannot check this assumption and will just assume it is true, and, if untrue, assume that we are just fitting the best linear model to the data.

The second assumption is ergodatic stationarity. Since this model is including trend and seasonal variables, we are eliminating the deterministic parts in the process and are satisfying this assumption. From the ACF plot, the process does look stationary but the residuals do appear serially correlated.

The third assumption is no perfect multicollinearity. When we fit our model, R did not report any warning or missing coefficients, which means that this assumption is violated.

The fourth assumption is the zero conditional mean assumption. We can evaluate this by looking at these residuals versus the fitted value plot, plotted below. If this assumption is satisfied, there should be no relationship between the fitted values and the residuals, a.k.a. there should be a straight line in the plot.

```{r echo = FALSE, message = FALSE, warning = FALSE}
augment(fit_quadratic_season) %>%
  ggplot(aes(x = .fitted, y = .innov)) +
  geom_point() +
  geom_smooth(se=FALSE)+
  scale_x_log10() +
  labs(title = "Seasonal Quadratic Model Residuals vs Fitted")
```

The line is curved, so we cannot justify that the zero conditional mean assumption is satisfied, meaning that there are likely additional variables that should be included in our model.

The fifth CLM assumption is homoskedasticity. The residuals are quite spread out with a large range of variance, so it seems as though this assumption is not satisfied.

The last assumption is no serial correlation. From our ACF plot, the residuals do appear to be serially correlated. Additionally, the Ljung Box test returns a high statistic with a small p-value. We can reject the null hypothesis that there is no autocorrelation and conclude that our residuals here are autocorrelated, thereby not satisfying this assumption.

The residuals do look close to a normal distribution, which gives us more confidence in our generated prediction intervals.

## ARIMA Modeling

Now, let's choose an ARIMA model to fit to the CO2 data. Recall that our EDA indicated that the CO2 data had the following characteristics: 

* non-stationary data series

* slowly decaying ACF plot, indicative of an AR process

* oscillating PACF plot, indicative of an MA process

* seasonal data

In order to transform the data into a stationary series, we can start by applying a first-order difference to the series and plotting the characteristics. 

```{r echo = FALSE, message = FALSE, warning = FALSE}

#first-order difference
first_diff <- co2_df %>%
  mutate(diff_co2 = difference(value)) 

co2_df %>%
gg_tsdisplay(difference(value),
               plot_type='partial', lag=36) +
  labs(title="First-order differenced", y="")
```

Based on the trend plot, the data seems to stabilize around a mean of -0.5, and it appears to have a constant variance, suggesting that the data only needs a first-order difference. The ACF plot continues to decay gradually but the oscillating behavior persists here. This indicates that the seasonal pattern is strong and stable after a first-order difference. As a result, we will want to use a seasonal difference in addition to this first difference. Since the seasonal behavior repeats every year, we will set m = 12, meaning the seasonal pattern repeats once every twelve months. The output of this seasonal model is below.

```{r echo = FALSE, message = FALSE, warning = FALSE}
#seasonally differenced
co2_s_diff <- co2_df %>%
  mutate(sdiff_co2 = difference(value, 12)) 

co2_s_diff

#plots for seasonal differencing
co2_df  %>%
gg_tsdisplay(difference(value, 12),
               plot_type='partial', lag=36) +
  labs(title="Seasonally differenced", y="")

```

On its own, seasonal differencing does not appear to make the data stationary. However, based on the ACF plot, we can confirm that the seasonal differencing either removes or significantly reduces the oscillation as it does not seem apparent anymore. As a result, we can conclude that we need both a first difference and a seasonal difference on the series. We can confirm these observations using the following unit root tests. We will first use the  Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test under the following hypothesis:

H0: The data are stationary

HA: The data are not stationary

```{r echo = FALSE, message = FALSE, warning = FALSE}
#unit root tests

co2_df %>%
  features(value, unitroot_kpss)

first_diff %>%
  features(diff_co2, unitroot_kpss)

co2_s_diff %>%
  features(sdiff_co2, unitroot_kpss )

```

We can interpret the tests in the following manner:

* For the undifferenced data, the test statistic (7.81) is bigger than the 1% critical value, so the p-value is less than 0.01, indicating that the null hypothesis is rejected. That is, the data are not stationary.

* For the first differenced data, the p-value is greater than 0.1, indicating the test fails to reject the null hypothesis. That is, the data are stationary.

* For the seasonally differenced data, the test statistic (1.94) is bigger than the 1% critical value, so the p-value is less than 0.01, indicating that the null hypothesis is rejected. That is, the data are not stationary.

Thus, we can conclude that we need both a first difference and a seasonal difference. But, how many differences do we need? To confirm that we are applying the appropriate amount of differences, we can use the following:

```{r echo = FALSE, message = FALSE, warning = FALSE}

#confirm the number of differences needed in the data
co2_df %>%
  features(value, unitroot_ndiffs)

first_diff %>%
  features(diff_co2, unitroot_ndiffs)

co2_s_diff %>%
  features(sdiff_co2, unitroot_ndiffs)

#test need for seasonal differencing; indicating one seasonal difference is required

co2_df %>%
  features(value, unitroot_nsdiffs)

first_diff %>%
  features(diff_co2, unitroot_nsdiffs)

co2_s_diff %>%
  features(sdiff_co2, unitroot_nsdiffs)
```

Here we can see that once we apply a first difference and a seasonal difference, the test returns 0, indicating no additional differences are required. It is important that we correctly identify the correct number of differences as we could potentially introduce false dynamics or autocorrelations into the time series.

```{r echo = FALSE, message = FALSE, warning = FALSE}
#double differenced
co2_df %>%
  gg_tsdisplay(difference(value, 12) %>% difference(),
               plot_type='partial', lag=36) +
  labs(title = "Double differenced", y="")
```

We will now use the ACF and PACF plots of our double differenced data to determine an appropriate ARIMA model via brute force. The significant spike at lag 3 in the ACF suggests a non-seasonal MA(3) component. The significant spike at lag 12 in the ACF suggests a seasonal MA(1) component. So, we might begin with an ARIMA(0,1,3)(0,1,1)12 model, indicating a first difference, a seasonal difference, and non-seasonal MA(3) and seasonal MA(1) component. The output of fitting this model appears below. 

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit1 <- arima(co2_df$value, order = c(0,1,3), seasonal= list(order = c(0,1,1), period = 12))
fit1
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
resid <- residuals(fit1)
residuals_plot <- autoplot(resid) + labs(title="Time Series of Residuals")
acf_plot <- ggAcf(resid) + labs(title="ACF of Residuals")


(residuals_plot / acf_plot)
```

```{r}

Box.test(resid,lag=10, fitdf=0, type="Lj")

```

The ACF plot indicates that the residuals are following a white noise process as each autocorrelation is close to zero and 95% of spikes lie within significance thresholds. There is one small but significant spike at lag 8. Additionally, since the p-value from the Box-Ljung test is greater than 0.05, we fail to reject the null hypothesis and conclude that there is no serial correlation in the data.

If we had evaluated the PACF as well, we may have chosen ARIMA(3,1,0)(1,1,1)12 model, indicating a first difference, a seasonal difference, non-seasonal AR(3) and MA(1) components, and seasonal AR(1) and AR(1) component. The significant spike at lag 3 in the PACF suggests a non-seasonal AR(3) component. The significant spike at lag 12 in the PACF suggests a seasonal AR(1) component. However, by comparing the AIC values of the first and second model, the first selection was a better fit based on the lower AIC value.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit2 <- arima(co2_df$value, order = c(3,1,1), seasonal= list(order = c(1,1,1), period = 12))
fit2
```

We can also try automatically fitting the model:

```{r echo = FALSE, message = FALSE, warning = FALSE}
#documentation seems outdated
#source_1:https://otexts.com/fpp2/seasonal-arima.html
#source_2:https://campus.datacamp.com/courses/forecasting-in-r/forecasting-with-arima-models?ex=10

auto_fit <- co2_df %>% model(ARIMA(value)) %>%  report()

```


```{r echo = FALSE, message = FALSE, warning = FALSE}
auto_fit %>% 
  gg_tsresiduals(lag=36) 


auto_resid <- residuals(auto_fit)
auto_resid
Box.test(auto_resid[3] ,lag=10, fitdf=0, type="Lj")

```

The trend and ACF plots indicate that the residuals of the automatically fitted ARIMA model are following a white noise process. Autocorrelations are close to zero and 95% of spikes lie within significance thresholds. There is one small but significant spike at lag 9. Also, since the p-value from the Box-Ljung test is greater than 0.05, we fail to reject the null hypothesis and conclude that there is no serial correlation in the data. However, the automatically fitted ARIMA model does not outperform our first guess as the AIC in the autofit model is higher. We will continue to proceed with the ARIMA(0,1,3)(0,1,1)12.

```{r echo = FALSE, message = FALSE, warning = FALSE}
future_d <- new_data(co2_df, n=25 * 12)

co2_df %>%
  model(ARIMA(value ~ 0 + pdq(0,1,3) + PDQ(0,1,1))) %>%
  forecast(new_data = future_d) %>%
  autoplot(co2_df ) +
  labs(x = 'Month of Year',
    y="CO2 (PPM)",
       title="CO2 measurements over time")

```

Again, we can see that these predictions continue to follow the trend and seasonal fluctuations that we noticed earlier in the data. However, our confidence intervals continue to widen with each year that we forecast. 

## Forecast atmospheric CO2 growth

If we generate predictions for when atmospheric CO2 is expected to be at 420 ppm and 500 ppm levels at the 95% confidence level, we can observe the wide confidence intervals noted in the previous graph. Predictions for 420ppm were as early as April 2022 and as late as December 2100. Surprisingly, when we make predictions on for 500ppm the confidence intervals narrow. According to this model's predictions, 500ppm CO2 levels will occur as early as March 2055 and as late as August 2086, as seen below.

```{r echo = FALSE, message = FALSE, warning = FALSE}
co2_ext_forecast <- forecast(fit1, h=103 * 12, level = c(95))
co2_ext_forecast <- summary(co2_ext_forecast)

ts.d  <- as.data.frame(as.yearmon(1998 + seq(0, 1235)/12))

forecast_df <- cbind(ts.d, co2_ext_forecast)
colnames(forecast_df )[1] <- "time_index"
colnames(forecast_df )[2] <- "point_forecast"
colnames(forecast_df )[3] <- "lo_95"
colnames(forecast_df )[4] <- "high_95"

forecast420ppm <- forecast_df %>%
 filter(round(point_forecast,0) == 420 | round(lo_95,0) == 420 | round(high_95,0) == 420)

min(forecast420ppm$time_index) 
max(forecast420ppm$time_index)

max(forecast420ppm$time_index) - min(forecast420ppm$time_index) 

forecast500ppm <-forecast_df %>%
 filter(round(point_forecast,0) == 500 | round(lo_95,0) == 500 | round(high_95,0) == 500)

min(forecast500ppm$time_index) 
max(forecast500ppm$time_index)

max(forecast500ppm$time_index) - min(forecast500ppm$time_index) 

forecast500ppm <-forecast_df %>%
 filter(round(point_forecast,0) == 500 | round(lo_95,0) == 500 | round(high_95,0) == 500)
```

When we look specifically at CO2 levels in 2100, we can expect the ppm values to be around 525 throughout the course of the year with fairly wide confidence intervals about 100ppms lower or higher. 

```{r echo = FALSE, message = FALSE, warning = FALSE}
sapply(forecast_df, class)

forecast_df %>%
 filter(year(time_index)==2100)

forecast_df %>%
 filter(year(time_index)==2100)%>%
  ggplot(aes(time_index, point_forecast)) + geom_point() + 
  geom_errorbar(aes(ymin = lo_95, ymax = high_95)) +
  labs(x = 'Month of Year',
    y="CO2 (PPM)",
       title="2100 CO2 predictions")
```

Based on the very wide confidence intervals, we're not very confident that these are accurate predictions. To assess the accuracy of our predictions more methodically, we can create a training set and a test set. From the plot, we can see that our predictions widen from the actuals with each consecutive year in just the last 8 years. While our predictions are probably a best guess given the information that we have, the ARIMA model assumes that seasonality is fixed over time, and this may be a strong assumption to make given that there are other factors that could likely impact CO2 over time. 

When we observe the residuals, we also notice that there are two significant spikes in the ACF plot at lag 3 and lag 9. Our p-value from the Box-Ljung test is also greater than 0.05, meaning that we fail to reject the null hypothesis of no serial correlation. However, since both of these observations are close to the significance threshold, this may be cause for concern around the predictive power of our model, particularly for such a far projection in time, as seen below. 

```{r echo = FALSE, message = FALSE, warning = FALSE}
#https://robjhyndman.com/hyndsight/longseasonality/
#https://otexts.com/fpp3/tscv.html

#creating training data
train <- co2_df %>% filter_index(. ~ "1989 Jan")
#train

fit_arima <- train %>% model(ARIMA(value))
report(fit_arima)

co2_fc <- fit_arima %>%
  forecast(h = 12 *8)

co2_fc  %>%
  autoplot(
    co2_df %>% filter(year(index) >= 1989),
    level = NULL
  ) +
  labs(
    y = "CO2 (ppm)",
    title = "Forecasts for co2 levels"
  ) +
  guides(colour = guide_legend(title = "Forecast"))

```

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_arima %>% 
  gg_tsresiduals(lag_max = 16)
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
augment(fit_arima) %>%
  features(.innov, ljung_box, lag = 16, dof = 6)
```


# Report From the Perspective of the Present

```{r load packages, echo = FALSE, message = FALSE, warning=FALSE}

list.of.packages <- c("latex2exp")


new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(tidyverse)
library(tsibble)
library(latex2exp)
library(magrittr)
library(patchwork)
library(lubridate)
library(feasts)
library(forecast)
library(zoo)
library(fable)
library(sandwich)
library(lmtest)
library(tseries)
library(gridExtra)

theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```

## Introduction 

We now ask the question of whether the data collected from January 1998 to the present has different characteristics which could lead us to additional or different conclusions than those which the dataset from 1958 until 1997 yielded.

We assume that the collection process for both datasets is identical.  On the website of the National Oceanic and Atmospheric Administration there is a note that the data collection process may have changed a

It is worth noting that the "present" dataset contains only about 24 years, or 293 months, compared to the 39 years, or 468 months contained in the "1997" dataset.


## Create a modern data pipeline for Mona Loa CO2 data.

As instructed we pulled created a pipeline to pull down the weekly Mona Loa CO2 data.

Within the dataset the weeks ending on dates; 2008-06-29, 2008-07-06 , 2008-07-13 , 2005-10-16, contained the measurement value -999.99, which cannot be accurate.  We "stubbed" those four dates with values similar to the weekly values for the weeks directly before or after.  We did not remove those data outright as doing so could cause problems within the utilization of the time series downstream.  


```{r echo = FALSE, message = FALSE, warning=FALSE}

#Create a data pipeline that starts by reading from the appropriate URL, and ends by saving an object called `co2_present` that is a suitable time series object. #load from National Oceanic and Atmospheric Web site.
#filter, mutate, and turn into tsibble object

#Grab Monthly Data -- May not use this.
co2_present_monthly <- read.table('https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt') %>%
  filter(V1 >= 1998)%>%
  mutate(index = yearmonth(as.yearmon(paste(V1, V2), "%Y %m"))) %>%
  mutate(value = V4) %>%
  mutate(log_value = log(V4)) %>% 
  dplyr::select(c("index","value","log_value")) %>%
  as_tsibble(index=index)

#In Examining this data there are two perios where collections are incorrect on a weekly basis.
# 1.  Period 
#545 2008-06-08 387.74 5.960335
#546 2008-06-15 388.11 5.961289
#547 2008-06-22 387.53 5.959793
#548 2008-06-29 -999.99 NaN
#549 2008-07-06 -999.99 NaN
#550 2008-07-13 -999.99 NaN
#    2005-10-16 -999.99 NaN
#
#Grab weekly data
co2_present <- read.table('https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.txt') %>%
  filter(V1 >= 1998)%>%
  mutate(index = as.Date(as.Date(paste(V1,V2,V3, sep="-")) )) %>%
  mutate(value = V5) %>%
  filter(value > 200) %>%
  mutate(log_value = log(value)) %>% 
  dplyr::select(c("index","value","log_value"))
  

#dates I'm manually putting values in.
index <- as.Date(c('2008-06-29','2008-07-06','2008-07-13','2005-10-16'))
value <- c(387.74,388.11,387.53,377.5)
log_value <- log(value)
df_insert <- data.frame(index,value,log_value)

co2_present <- bind_rows(
  co2_present,
  df_insert
) %>% as_tsibble(index=index)

#Aggregate the weekly to monthly
co2_present_weekly_agg_monthly <- as.data.frame(co2_present) %>%
  filter(year(index) >= 1998)%>%
  mutate(index = yearmonth(index)) %>%
  group_by(index)  %>% 
  summarize(value=mean(value))  %>% 
  mutate(log_value = log(value)) %>% 
  dplyr::select(c("index","value","log_value")) %>%
  as_tsibble(index=index)

```


```{r echo = FALSE, message = FALSE}

#old data
co2_ts <- tsibble::as_tsibble(co2) %>%
  mutate(log_value = log(value))

plot_1997 <- co2_ts %>%
  ggplot + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Monthly Mean $CO_2$ 1958 through 1997)'),
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

hist_1997 <- co2_ts %>%
  ggplot(aes(x=value)) + geom_histogram(bins=8) + labs(title="Histogram 1958 through 1997")
acf_1997 <- ggAcf(co2_ts$value, lag.max=(15*12)) + labs(title="ACF 1958 through 1997")
pacf_1997 <- ggPacf(co2_ts$value, lag.max=(15*12)) + labs(title="PACF 1958 through 1997")


plot_present <- co2_present %>%
  ggplot + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Weekly Mean $CO_2$)'),
    subtitle = " 1998 through Present",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )
hist_present <- co2_present %>%
  ggplot(aes(x=value)) + geom_histogram(bins=8) + labs(title="Histogram 1998 through Present")
acf_present <- ggAcf(co2_present$value, lag.max=(15*12)) + labs(title="ACF 1998 through Present")
pacf_present <- ggPacf(co2_present$value, lag.max=(15*12)) + labs(title="PACF 1998 through Present")
#acf_present
#pacf_present
plot_present + acf_present + hist_present + pacf_present + plot_layout(design = "
AAAAACCCC
AAAAACCCC
BBBBBCCCC
BBBBBCCCC
DDDDDCCCC
DDDDDCCCC
")



```

As with the "1997" dataset, we see a clear increasing trend with the same seasonal "wave" pattern.  Seasonal fluctuation does not appear to increase with time, suggesting, again, that an additive model explains the decomposition in this series.  The time series is not stationary, as its mean increases.  Variance presents as constant.

The ACF displays a slow, over-time, decline consistent with a trending time series.  While the ACF plot of the "1997" plot remains above the significance line until lag 140, this ACF plot never crosses the significance line.  

The PACF of this time series has a strong postive spike a lag 1 followed by a pattern consistant with partial autocorrelation.

Our histogram of has no values lower than 365, or nigher than 421, and that these values are not normally distributed.

In order to better understand the differences between these two datasets we examine them side by side.

```{r echo = FALSE, message = FALSE}

plot_present + plot_1997 + hist_present + hist_1997 + plot_layout(design = "
AAAAACCCC
AAAAACCCC
BBBBBDDDD
BBBBBDDDD
")

```

When we start looking graphing the two datasets side by side, the difference of one containing 39 years, and the other 24, begins to hamper our understanding.

We take only the last 293 months of the "1997" dataset and graph it on the same space as the "present" dataset.

```{r echo = FALSE, message = FALSE}


co2_df_1 <-
  co2_ts %>%
  mutate(id = row_number())  %>%
  filter(id > 175) %>%
  mutate(id = row_number()) %>%
  dplyr::select("id","value")  %>%
  as_tsibble()
  #dplyr::select("id","1972 through 1997")

co2_present_df <-
  as.data.frame(co2_present_weekly_agg_monthly) %>%
  mutate(id = row_number()) %>%
  #mutate("1997 through present"=value) %>%
  dplyr::select("id","value")

min_1997 = min(co2_df_1[,2], na.rm=T)
min_present = min(co2_present_df[,2], na.rm=T)

max_1997 = max(co2_df_1[,2], na.rm=T)
max_present = max(co2_present_df[,2], na.rm=T)

delta_1997 = max_1997 - min_1997
delta_present = max_present - min_present

delta_between_periods = delta_present - delta_1997



ochart_1 <- ggplot() +
   geom_line(data=co2_df_1,
             aes(x=id,y=value, color="1973 through 1997"),
             size=1.2) +
   geom_line(data=co2_present_df,
             aes(x=id,y=value, color="1997 through present"),
             size=1.2) +
  labs(x = "Months",
       y = TeX(r'($CO_2$ parts per million)'),
       title="293 month comparison: 1973 through 1997, and 1998 through present.") +
     scale_color_manual(name='Periods',
                     breaks=c('1973 through 1997', '1997 through present'),
                     values=c('1973 through 1997'= '#ebcc34' , 
                              '1997 through present'='#eb3434'))
ochart_1



```

In the 293 months prior to Dec 31, 1997, the atmospheric CO2 rose by `r delta_1997` PPM.  By comparison, in the 293 months prior to May 31, 2022 (the most recent month we have a measurement for), the atmospheric CO2 rose by `r delta_present` PPM.  This is a difference of `r delta_between_periods` PPM during the same time interval.  This could indicate an acceleration in the increase in PPM.

We apply the same "parsing" of the original "1997" dataset and compare the parsed dataset's ACF and PACF graphs to those of the "present" dataset.

```{r echo = FALSE, message = FALSE}

acf_1997 <- ggAcf(co2_df_1$value, lag.max=(15*12)) + labs(title="ACF (monthly avg) 1973 to 1997")
pacf_1997 <- ggPacf(co2_df_1$value, lag.max=(15*12)) + labs(title="PACF (monthly avg) 1973 to 1997")

   (acf_1997 | acf_present + labs(title="ACF (weekly avg) 1998 to Present")) /
   (pacf_1997 | pacf_present + labs(title="PACF (weekly avg) 1998 to Present"))  +
  plot_annotation(
      title    = 'ACF and PACF comparison',
    #  subtitle = 'Could be Random Walk',
      tag_levels = 'A')  

```
Parsing the "1997" dataset, to include 293 months only, yields a ACF which crosses the significance line 100, while the weekly data does not cross the significance line.  We notice that the amplitude of oscillation on the "1997" datasets' ACF, is greater than the amplitude of oscillation in the "present" dataset's ACF.

Next we examine the seasonality of the "present" comparing it to the "1997" seasonality.

In order to the present dataset's seasonality 1997 seasonality we aggregate values within the weekly dataset to monthly values, for the purpose of this comparison.

```{r echo = FALSE, message = FALSE, fig.width=6, fig.height=5, warning=FALSE}

df_3_year_season_org <- co2_ts %>%
  filter(year(index)>= 1993)%>%
  select("index","value")

co2_present_no_log <- co2_present_weekly_agg_monthly %>%
  filter(year(index)>= 2017)%>%
  select("index","value")

combined_no_log_latest <- bind_rows(
  df_3_year_season_org,  
  co2_present_no_log
)

seasons_present <- ggseasonplot(x = as.ts(combined_no_log_latest), year.labels=TRUE, year.labels.left=TRUE) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Seasonal plot: Monthly mean $CO_2$)'))


seasons_present

```

In the plot above we look at the last 5 years in the "1997" dataset and the last 5 years of the "present" dataset.  

What we are trying to ascertain is if the seasonality has become more extreme.  It is difficult to ascertain if the seasonality has become more extreme based on the graph above.  

We next compare the two subseries graphs looking at each dataset.


```{r echo = FALSE, message = FALSE, fig.width=6, fig.height=4, warning=FALSE}

co2_df_1_ts <-
  co2_ts %>%
  mutate(id = row_number())  %>%
  filter(id > 175) %>%
  mutate(id = row_number()) %>%
  dplyr::select("index","value")  %>%
  as_tsibble()

subseries_1997 <- ggsubseriesplot(x = as.ts(co2_df_1_ts)) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Subseries plot: Monthly mean $CO_2$ 1973 through 1997)'))

subseries_present <- ggsubseriesplot(x = as.ts(co2_present_no_log)) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Subseries plot: Monthly mean $CO_2$ 1998 through 2022)'))


subseries_1997 + subseries_present + plot_layout(design = "
AAAAA
BBBBB
")


```

With this new plot it becomes clearer that the yearly oscillations in PPM are more extreme in the present dataset than in the one ending in 1997.

That is to say the seasonality effect shows a noticeable increase in the magnitude of the fluctuations in the second dataset.

We now remove the seasonal fluctuations in both datasets and graph the increase in atmospheric CO2 PPM.

In order to do this we aggregate our weekly data to monthly data in order to compare on the same scales.

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=6, fig.height=3}

co2_df_1 <-
  co2_ts %>%
  mutate(id = row_number())  %>%
  filter(id > 175) %>%
  mutate(year = year(index))  %>%
  index_by(year) %>%
  summarise(avg_value = (sum(value)/12)) %>%  
  mutate(id = row_number()) %>%
  filter(id > 1 ) %>%  
  dplyr::select("id","avg_value")
  #dplyr::select("id","1972 through 1997")

co2_present_df <- co2_present_weekly_agg_monthly %>%
  mutate(year = year(index))  %>%
  index_by(year) %>%
  summarise(avg_value = (sum(value)/12)) %>%  
  mutate(id = row_number())  %>%
  filter(id <= 24) %>%  
  dplyr::select("id","avg_value")


ochart_2 <- ggplot() +
   geom_line(data=co2_df_1,
             aes(x=id,y=avg_value, color="1973 through 1997"),
             size=1.2) +
   geom_line(data=co2_present_df,
             aes(x=id,y=avg_value, color="1997 through present"),
             size=1.2) +
  labs(x = "Months",
       y = TeX(r'($CO_2$ parts per million)'),
       title="293 month comparison: 1973 through 1997, and 1998 through present.",
       subtitle = "Smoothed") +
     scale_color_manual(name='Periods',
                     breaks=c('1973 through 1997', '1997 through present'),
                     values=c('1973 through 1997'= '#ebcc34' , 
                              '1997 through present'='#eb3434'))
ochart_2


```


We now perform additive and multiplicative decomposition to remove the trend and seasonal movements from our dataset to confirm that the 


```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=7.5, fig.height=6}
co2_present_monthly <- co2_present %>%
  mutate(log_value = log(value))

dcmp_add <- co2_present %>%
  model(stl = STL(value))

dcmp_multi <- co2_present %>%
 model(stl = STL(log_value))

decomp <- components(dcmp_add) %>% autoplot()
residuals <- components(dcmp_add)%>%
  ACF(remainder) %>%
  autoplot() + labs(title="Additive residuals")
log_decomp <- components(dcmp_multi) %>% autoplot()
log_residuals <- components(dcmp_multi) %>%
  ACF(remainder) %>%
  autoplot() + labs(title="Multiplicative residuals")

grid.arrange(decomp, residuals, log_decomp, log_residuals, nrow = 2, ncol = 2)
```

These graphs confirm that the time series is trending upwards.  In the additive decomposition plots (top left), we see that seasonal fluctuations increase over time.  This confirms our side-by-side graph above showing the increase in seasonal fluctuations between the two time series.

The multiplicative "season_year" decomposition graph is stable, and not visibly increasing.  This means like the "1997" time series, the "present" time series may be multiplicative.

Both residuals plots, again, show our time series as stationary, but not white noise.  This means correlation in the data still exists.

Next we run the ADF test, as well as the PP test to see if the time series is stationary.

H0: The data are not stationary
HA: The data are stationary

```{r echo = FALSE, message = FALSE, warning = FALSE}

co2_present_ts = as.ts(co2_present$value)

adf.test(co2_present_ts, alternative="stationary", k=5)
pp.test(co2_present_ts)


```

The tests above indicate that we can reject the null hypothesis that the time series is non-stationary.

The Unit Root tests above indicate that this time series is difference stationary.  

This contradicts our visual EDA, which shows a changing mean, given the strong upward trend.  

We should note that the tests above are testing whether the time series are difference stationary.  We apply a linear model and then graph its residuals.

```{r echo = FALSE, message = FALSE}
library(lmtest)

trModel <- lm(co2_present_ts ~ c(1:length(co2_present_ts)))

checkresiduals(trModel) 

```

Graphing the residuals appears to show a mean reverting process.  That is to say the residuals are stationary and not trending, and appear to be normally distributed.

The oscillating ADF appears to show seasonality.

Finally, we run an ADF and PP test on the residuals, and we again, see that the null hypothesis of non-trend-stationary can be ignored.

H0: The data are not stationary
HA: The data are stationary


```{r echo = FALSE, message = FALSE}

adf.test(trModel$residuals, alternative="stationary", k=5)
pp.test(trModel$residuals, alternative="stationary")

```

Despite the fact that the ADF and PP tests indicate the data series is stationary, our visual analysis of this data set suggests that it is non-stationary as its mean is increasing over time.  We will ignore the ADF and PP test results as they can sometimes be of low power.

## Compare linear model forecasts against realized CO2

In section 1 we fit two models, one linear model and one quadratic model.  In this section we're going to compare both models to the "present" data set and see how well they predict future data.

### Simple linear model with no polynomial terms or seasonality

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=6, fig.height=6}

future_df <- new_data(co2_ts, n=23 * 12)

fit_linear <- co2_ts %>%
  model(trend_model = TSLM(value ~ trend()))

lm_prediction_based_on_1997_data <- fit_linear %>%
  forecast(new_data = future_df) %>%
  autoplot() +  
  labs(
    title = TeX(r'(Predicted Monthly Mean $CO_2$)'),
    subtitle = "Linear Model ",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

data_and_lm_prediction_overlay <- fit_linear %>%
  forecast(new_data = future_df) %>%
  autoplot(co2_present) +  
  labs(
    title = TeX(r'(Weekly Mean $CO_2$)'),
    subtitle = "(Series, with Linear Prediction Overlay)",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

(plot_present | lm_prediction_based_on_1997_data) /
  data_and_lm_prediction_overlay

```

The simple linear model above which uses only trend as a coefficient has a slope that is too shallow to be useful in prediction.

### Quadradic model with polynomial terms and seasonality

Below, we utilize a model with polynomial terms and seasonality.

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=6, fig.height=6}

future_df <- new_data(co2_ts, n=23 * 12)

fit_quadratic <- co2_ts %>%
   model(trend_model = TSLM(value ~ trend()+I(trend()^2))) 

fit_quadratic_season <- co2_ts %>%
  model(trend_model = TSLM(value ~ trend() + I(trend()^2) + season())) 

lm_prediction_based_on_1997_data <- fit_quadratic_season %>%
  forecast(new_data = future_df) %>%
  autoplot() +  
  labs(
    title = TeX(r'(Predicted Monthly Mean $CO_2$)'),
    subtitle = "Quadratic Model w/ Trend & Seasonal Effects",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

data_and_lm_prediction_overlay <- fit_quadratic_season %>%
  forecast(new_data = future_df) %>%
  autoplot(co2_present) +  
  labs(
    title = TeX(r'(Weekly Mean $CO_2$)'),
    subtitle = "(Series, with Quadratic Prediction Overlay)",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

(plot_present | lm_prediction_based_on_1997_data) /
  data_and_lm_prediction_overlay

```

In the top-left, we plot the 1998-present time series, next to it, we plot the prediction yielded by the best-fitting model with polynomial terms and seasonality, model we developed against the "1997" data set.  Beneath the two plots we overlay the original time series with the prediction.  Towards the middle of time time series, the fit is nearly perfect.  At both the beginning and end of the time series, there are barely visible differences the prediction and the "real" underlying time series.  

We predict 23 years from Dec 31, 1997, which means the predict values are through December 31 2021.  Our "present" time series contains data "through" May 2022, which means we have an addition 5 months of data, indicated by the solid black line extending upwards out of the prediction.

The linear model is very accurate.

## Compare ARIMA models forecasts against realized CO2  


```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=6, fig.height=6}


future_d <- new_data(co2_ts, n=23 * 12)

data_and_arima_prediction_overlay <- co2_ts %>%
  model(ARIMA(value ~ 0 + pdq(0,1,3) + PDQ(0,1,1))) %>%
  forecast(new_data = future_d) %>%
  autoplot(co2_present)  +
  labs(
    title = TeX(r'(Weekly Mean $CO_2$)'),
    subtitle = "(Series, with ARIMA Prediction Overlay)",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

arima_prediction_based_on_1997_data<-co2_ts %>%
  model(ARIMA(value ~ 0 + pdq(0,1,3) + PDQ(0,1,1))) %>%
  forecast(new_data = future_d) %>%
  autoplot() +  
  labs(
    title = TeX(r'(Predicted Monthly Mean $CO_2$)'),
    subtitle = "(ARIMA Model w/ Trend & Seasonal Effects)",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

(plot_present | arima_prediction_based_on_1997_data) /
  data_and_arima_prediction_overlay
#plot_present
#arima_prediction_based_on_1997_data
#data_and_arima_prediction_overlay

```

In the top-left graph, we plot the 1998-present time series, next to it, we plot the prediction yielded by the best-fitting ARIMA model we developed against the "1997" data set.  Beneath the two plots we overlay the original time series with the prediction.  The overlay shows a divergence between predicted ARIMA values and the actual trend.  

We predict 23 years from Dec 31, 1997, which means the predict values are through December 31 2021.  Our "present" time series contains data "through" May 2022, which means we have an addition 5 months of data, indicated by the solid black line extending upwards out of the prediction.

The ARIMA model does not predict as accurately as the quadradic model.

To demonstrate this we graph both on top of one another below.


```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=6, fig.height=6}

data_and_lm_prediction_overlay / 
  data_and_arima_prediction_overlay

```   

## Evaluate the performance of 1997 linear and ARIMA models

In 1997 you made predictions about the first time that CO2 would cross 420 ppm. How close were your
models to the truth?
After reflecting on your performance on this threshold-prediction task, continue to use the weekly data to
generate a month-average series from 1997 to the present, and compare the overall forecasting performance
of your models from Parts 2a and 3b over the entire period. (You should conduct formal tests for this task.)

```{r, message=FALSE, echo=FALSE, warning=FALSE}
# display TS for atmospheric co2 for when we crossed 420ppm
# suggests 2021-04-25, different from forecasted april 2022 from 1997 and was not within our interval of April 2022 - December 2100
head(co2_present %>% filter(value>=420))

# aggregation
co2_present_weekly_agg_monthly <- as.data.frame(co2_present) %>%
  filter(year(index) >= 1998)%>%
  mutate(index = yearmonth(index)) %>%
  group_by(index)  %>%
  summarize(value=mean(value))  %>%
  mutate(log_value = log(value)) %>%
  dplyr::select(c("index","value","log_value")) %>%
  as_tsibble(index=index)

# model forecasts chosen form 2a
fit_linear_2a = fit_linear
predictions_2a <- forecast(fit_linear, h = 1000)
accuracy_lm = accuracy(predictions_2a, co2_present_weekly_agg_monthly)

pe_420 = predictions_2a %>% filter(.mean>=420)
pe_420 = min(pe_420$index)

# first fit model 3a
forecast420ppm <- forecast_df %>%
 filter(round(point_forecast,0) == 420 | round(lo_95,0) == 420 | round(high_95,0) == 420)

forecast420pf <- forecast_df %>%
 filter(round(point_forecast,0) == 420)

fit_3a <- co2_df %>%
  model(
    arima_fit = ARIMA(value~0+pdq(0,1,3)+PDQ(0,1,1, period=12)),
  )

forecast_3a <- forecast(fit_3a, h=103 * 12, level = c(95))
accuracy_arima = accuracy(forecast_3a, co2_present_weekly_agg_monthly)
print('Forecasts from 1997 report')
sprintf("Point Forecast LM: %s",pe_420)
sprintf("Point Forecast ARIMA: %s",min(forecast420pf$time_index))
sprintf("Lower bound forecast ARIMA: %s",min(forecast420ppm$time_index))
sprintf("Upper bound forecast ARIMA: %s",max(forecast420ppm$time_index))
```

From our present $CO_2$ data, we observe that the date that Mona Lua crossed 420 ppm was on April 25, 2021. When comparing these across the models in the 1997 report: in the `trend model`, it is forecasted that 420ppm will not be reached until December 2041, whereas the point forecast for the ARIMA model is April 2032. The `arima fit` also had a 95% confidence interval for 420ppm where lower bound is a very wide range of April 2022 and upper bound is December 2100. Concluding, our observed actual does not match what were forecasted in either of the models. Further, our observed date is also outside of the range of the confidence interval for their estimated ARIMA model. Let's next compute and observe the accuracies of both the linear model and ARIMA model that were estimated in 1997.

```{r, message=FALSE, echo=FALSE, warning=FALSE}
accuracy_lm
accuracy_arima
```

Within these accuracy measurements displayed we will choose to talk about RMSE for the remainder of this analysis. The RMSE, or Root Mean Squared Error is the standard deviati0on of the observed residauls and is used to measure the overall spread of residuals, and in our context will be used to assess the accuracy of our model fits. The RMSE of the `trend model` is `13.7` whereas the RMSE of the `arima fit` is `8.26`, concluding that the `arima fit` is the more accurate model of the two. Which is loosely true, though `arima fit` did not have confidence bounds for forecasted date of observed 420ppm, it still has a point estimate that is closer than that of the `trend model`.


## ARIMA modeling

Let's choose an ARIMA model to fit the present CO2 data from NOAA. First we will assess two datasets and two models, one dataset for seasonally adjusted data (SA) and one for non-sesonally adjusted data (NSA). Then, within both datasets, we will split the data into test and train sets with the last two years of data being the test set. Following the report from 1997 and observing the time series we have for our 1998-present data of $CO_2$ we will conclude with also applying linear differencing methods to our time series.

```{r, message=FALSE, echo=FALSE, warning=FALSE}

sa_co2_present_test <- co2_present_weekly_agg_monthly %>%
  filter(index>=as.Date("2020-01-01")) %>%
  model(stl = STL(value)) %>% 
  components()
sa_co2_present_train <- co2_present_weekly_agg_monthly %>%
  filter(index < as.Date("2020-01-01")) %>%
  model(stl = STL(value)) %>% 
  components()

nsa_co2_present_test <- co2_present_weekly_agg_monthly %>%
  filter(index>=as.Date("2020-01-01"))
nsa_co2_present_train <- co2_present_weekly_agg_monthly %>%
  filter(index < as.Date("2020-01-01"))

```

### Seasonally adjusted data assessment

Now that we have all of our necessary data, let's get to creating models for both. First let's assess the number of differences needed for the seasonally adjusted data to be stationary, since this data already has the season component stripped out, we know there are no seasonal differences needed. Let's also assess the acf and pacf. 

Assessing the ACF and PACF plots below, the ACF has a slow decay while the PACF has a large spike at lag 1, indicating that this series has a unit root and that the process is of AR(1). 


```{r, echo=FALSE, message=FALSE}
sa_acf <- ggAcf(sa_co2_present_train$season_adjust, lag.max=(50)) + labs(title="Seasonally adjusted ACF")
sa_pacf <- ggPacf(sa_co2_present_train$season_adjust, lag.max=(50)) + labs(title="Seasonally adjusted PACF")
sa_acf / sa_pacf
```


Next, we run a KPSS test to test for stationarity, and since the pvalue is smaller than 0.05 critical value, we know the data is not stationary. We then run ndiffs to check how many differences are needed to make the data stationary, which is 1. Let's next difference the data once and assess the ACF and PACFs again.
```{r, echo=FALSE, message=FALSE}
sa_co2_present_train %>%
  features(season_adjust, unitroot_kpss)

sa_co2_present_train %>%
  features(season_adjust, unitroot_ndiffs)
```

```{r SA differenced ACF and PACF, echo=FALSE, message=FALSE}
sa_co2_present_train <- sa_co2_present_train %>% mutate(sa_one_diff = difference(season_adjust)) 

sa_acf <- ggAcf(sa_co2_present_train$sa_one_diff, lag.max=(50)) + labs(title="Seasonally adjusted ACF 1 diff")
sa_pacf <- ggPacf(sa_co2_present_train$sa_one_diff, lag.max=(50)) + labs(title="Seasonally adjusted PACF 1 diff")

sa_acf / sa_pacf
```

Looking at the SA differenced ACF and PACF, the significant spike at lag=1 in the ACF suggests a non-seasonal MA(1) component while the PACF yields no new information. Let's fit a couple of models to compare, one being an $ARIMA(1,1,1)$ and one that is automatically computed through the `ARIMA` func call.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
sa_our_model = Arima(sa_co2_present_train$season_adjust,order=c(1,1,1), include.drift=TRUE)
sa_our_model

sa_arima_fit = sa_co2_present_train %>% model(ARIMA(season_adjust))
report(sa_arima_fit)
```
Assessing the summaries from the model we chose to fit $ARIMA(1,1,1)$ with drift and without a seasonal-ARIMA process, we get an $AIC = 118$ and $BIC = 132$. Furthermore, the algorithmically chosen model gave an $ARIMA(0,1,1)(0,0,1)[12]$ model, which the automatic call includes a season-ARIMA component, with $AIC = 109$ and $BIC = 124$. In either models, we observe that the automatic model yields lower AIC and BIC values, which should lead us to choose $ARIMA(0,1,1)(0,0,1)[12]$. However, because we are using seasonally adjusted data we would like to carry forward with the model we have estimated $ARIMA(1,1,1)$ which does not contain seasonal components.

Now that we have our model, let's check the residuals for stationarity.

```{r Resid TS and resid ACF, echo=FALSE, message=FALSE, warning=FALSE}
sa_resid = residuals(sa_our_model)
(autoplot(sa_resid) +  labs(title="Residual Plot SA Model")) /
(ggAcf(sa_resid) +  labs(title="ACF Plot SA Model"))
```
```{r box jung, echo=FALSE, message=FALSE, warning=FALSE}
Box.test(sa_resid,lag=15, fitdf=0, type="Lj")
```
From observing the residual plot, the data loosely resembles that of white noise, while the ACF of the residuals suggests that the data is stationary, with a small lag spike at lag=23 and the rest of the lags within the 95% bounds. Assessing the results from the Ljung-Box test, we have a p-value that is much larger than the 0.05 critical value leading us to fail to reject the null hypothesis and conclude that there is no serial correlation within our time series.

### Non-seasonally adjusted data assessment

Let's follow the same procedure above for the NSA data. Furthermore, we know there is a seasonal component to this data so let's see how many differences it will take for the data to become stationary. We will also observe the PACF and ACF plots of the NSA data.

From the below metrics we've found that 1 non-seasonal difference and 1 seasonal difference is needed.

```{r, message=FALSE, echo=FALSE}
nsa_co2_present_train %>%
  features(value, unitroot_ndiffs)

nsa_co2_present_train %>%
  features(value, unitroot_nsdiffs)
```

```{r, message=FALSE, echo=FALSE, warning=FALSE}
nsa_co2_present_train <- nsa_co2_present_train %>% mutate(diffed = difference(value) %>% difference(lag=12))

nsa_acf <- ggAcf(nsa_co2_present_train$diffed, lag.max=(50)) + labs(title="Non seasonally adjusted ACF double difference")
nsa_pacf <- ggPacf(nsa_co2_present_train$diffed, lag.max=(50)) + labs(title="Non seasonally adjusted PACF double difference")

nsa_acf / nsa_pacf
```

The ACF of the doubly differenced NSA time series shows a significant spike at lag=1 and lag=12 indicating that we need non-seasonal MA(1) and seasonal MA(1) components respectively. In the PACF there is 1 significant spike at lag=1 suggesting a non-seasonal AR(1) while there is also a signifncant spike at lag=12 and lag=24 indicating a non-seasonal AR(2) component. 

Now let's fit two models, same as before. One that is automatically chosen for us and another one by our assessment, which will be an $ARIMA(1,1,1)(2,1,1)[12]$ model.
```{r, message=FALSE, echo=FALSE, warning=FALSE}
nsa_our_model2 = Arima(nsa_co2_present_train$value, order=c(1,1,1), seasonal= list(order = c(2,1,1), period = 12))
nsa_our_model2

nsa_arima_fit = nsa_co2_present_train %>% model(ARIMA(value))
report(nsa_arima_fit)
nsa_our_model = Arima(nsa_co2_present_train$value, order=c(1,1,2), seasonal=list(order=c(0,1,1), period=12))
```
Observing the above summaries of both estimated models: the BIC is lower in the automatically generated model $ARIMA(1,1,2)(0,1,1)[12]$. We also observe that our assessments were correct and not too far off from what the auto ARIMA call concluded with. Because we are using BIC as the main criteria of model selection, we will select the algorithmically computed model as our model ($ARIMA(1,1,2)(0,1,1)[12]$) of interest.

Next, we should check the residuals and run tests on the model we have estimated.

```{r, echo=FALSE, message=FALSE}
nsa_resid = residuals(nsa_our_model)
(autoplot(nsa_resid) + labs(title="Residual Plot NSA Model")) /
(ggAcf(nsa_resid) + labs(title="ACF Plot NSA Model"))
```

```{r,echo=FALSE, message=FALSE}
Box.test(nsa_resid,lag=15, fitdf=0, type="Lj")
```

From the results of the ACF of residuals, we observe that all lags are within the significant 95% threshold which means it closely resembles that of a white noise. The time series plot of the residuals loosely resemble that of a white noise, with fluctuations floating around 0 and very rarely crossing 1 and -1. From the Ljung-Box test, we observe a p-value that is higher than 0.05 critical value, leading us to reject the null hypothesis and conclude that there is no correlation within our time series. 

From these results we will continue with using $ARIMA(1,1,1)$ for our seasonally adjusted time series, and $ARIMA(1,1,2)(0,1,1)[12]$ for our non-seasonally adjusted time series.

### Assessing model accuracy

With creating and assessing the goodness of fit of so many models, we'd also like to observe how well our models can do against our test data. In order to do so, we will measure the accuracy of our models against a test set while also observing their forecasts into the future.

* First, we create forecasts two years into the future with both models.
* Next, we will compute the accuracy measurements of both models.
* And finally, we will also train a polynomial time-trend model to the seasonally adjusted series and run the same accuracy computations as previous models.

Here are the cross validation results of the seasonally adjusted time series:
```{r, message=FALSE, echo=FALSE}
# compute predictions and assess accuracy
sa_predictions <- forecast(sa_our_model, h = 2*12+7)
sa_accuracy = accuracy(sa_predictions, sa_co2_present_test$season_adjust)
sa_accuracy
```

And below are the cross validation results of the non-seasonally adjusted time series:
```{r, message=FALSE, echo=FALSE, warning=FALSE, warn = FALSE}
# compute predictions and assess accuracy
nsa_predictions <- forecast(nsa_our_model, h = 2*12+7)
nsa_accuracy = accuracy(nsa_predictions, nsa_co2_present_test$value)
nsa_accuracy
```

Looking at the RMSE of both models against our test set, we observe that the model fitted to the non-seasonally adjusted data yields a lower RMSE (0.398) compared to the seasonally adjusted model with an RMSE of 0.54. Let's take a look at the forecasting abilities descriptively below.

```{r echo = FALSE, message = FALSE, warning = FALSE}
# Compute predictions and assess accuracy
# BASED ON VALUE
nsa_future_d <- new_data( nsa_co2_present_train, n = (2*12) + 7 )
real_test_values <- autoplot(nsa_co2_present_test)  +
    labs(
      title = "Actual Time Series",
      subtitle = "Non-season adjusted data",
      x = 'Month and Year',
      y = TeX(r'($CO_2$ parts per million)')
    )
#Arima(nsa_co2_present_train$value, order=c(2,1,0), seasonal= list(order = c(0,1,1), period = 12))
prediction_on_test_values <- nsa_co2_present_train %>%
   model(ARIMA(value ~ 0 + pdq(2,1,0) + PDQ(0,1,1))) %>%
    forecast(new_data = nsa_future_d) %>%
    autoplot()  +
    labs(
      title = "ARIMA Prediction",
      subtitle = "Non-season adjusted data",
      x = 'Month and Year',
      y = TeX(r'($CO_2$ parts per million)')
    )
data_and_arima_prediction_overlay1 <- nsa_co2_present_train %>%
   model(ARIMA(value ~ 0 + pdq(2,1,0) + PDQ(0,1,1))) %>%
    forecast(new_data = nsa_future_d) %>%
    autoplot(nsa_co2_present_test)  +
    labs(
      title = "Series, with ARIMA Prediction Overlay",
      subtitle = "Non-season adjusted data",
      x = 'Month and Year',
      y = TeX(r'($CO_2$ parts per million)')
    )
( real_test_values | prediction_on_test_values ) / 
data_and_arima_prediction_overlay1
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
# compute predictions and assess accuracy
# BASED ON VALUE
# am here
my_sa_copy <- sa_co2_present_test %>%
  select("index","season_adjust") %>%
  mutate(value=season_adjust) %>%
  select("index","value")%>%
  as_tsibble(index=index)
sa_co2_present_test1 <-sa_co2_present_test %>%
  mutate(value=season_adjust)%>%
  rename(old_model = .model)
sa_co2_present_train1 <- sa_co2_present_train %>%
  mutate(value=season_adjust)%>%
  rename(old_model = .model)
sa_future_d <- new_data(sa_co2_present_train1, n = (2*12) + 7 )

real_test_values <- autoplot(my_sa_copy)  +
    labs(
      title = "Actual Time Series",
      subtitle = "Season adjusted data",
      x = 'Month and Year',
      y = TeX(r'($CO_2$ parts per million)')
    )

prediction_on_test_values <- sa_co2_present_test1 %>%
   model(ARIMA(value ~ pdq(1,1,1) )) %>%
    forecast(new_data = sa_future_d) %>%
    autoplot()  +
    labs(
      title = "ARIMA Prediction",
      subtitle = "Season adjusted data",
      x = 'Month and Year',
      y = TeX(r'($CO_2$ parts per million)')
    )
data_and_arima_prediction_overlay1 <- sa_co2_present_test1 %>%
   model(ARIMA(value ~ pdq(1,1,1) )) %>%
    forecast(new_data = sa_future_d) %>%
    autoplot(sa_co2_present_test1)  +
    labs(
      title = "Series, with ARIMA Prediction Overlay",
      subtitle = "Season adjusted data",
      x = 'Month and Year',
      y = TeX(r'($CO_2$ parts per million)')
    )
( real_test_values | prediction_on_test_values ) / 
data_and_arima_prediction_overlay1
```
With the NSA data, we observe that the predicted values are very similar to the actual values, nearly 100% following the pattern that is observed in the actual data from Jan 2020 to May 2022. Conversely, with the predicted values of the model fitted to the SA data, we observe that the model does not perform as well and is not as accurate. It seems as though the predicted values are about a constant amount above the actual values of $CO_2$


And now, we will fit a polynomial time trend model to the seasonall adjusted series.
```{r, message=FALSE, echo=FALSE, warning=FALSE, warn = FALSE}

sa_fit_quadratic <- sa_co2_present_train %>%
  model(lm=TSLM(season_adjust ~ trend + I(trend^2)))

sa_fit_quadratic %>% report()

# the forecast call is erring out :/
#sa_quad_preds <- sa_fit_quadratic %>% forecast(new_datadata=future_d)
#sa_quad_acc = accuracy(sa_quad_preds, sa_co2_present_test$season_adjust)
```
# TODO


## How bad could it get?

With the non-seasonally adjusted data series, generate predictions for when atmospheric CO2 is expected
to be at 420 ppm and 500 ppm levels for the first and final times (consider prediction intervals as well as
point estimates in your answer). Generate a prediction for atmospheric CO2 levels in the year 2122. How
confident are you that these will be accurate predictions?

Next, the question arose from a colleague of whether our model could predict the first and final times that the $CO_2$ levels would be 420ppm and 500ppm, we figured in doing so we could forecast how high the $CO_2$ levels could reach with the current state of the world, according to the NSA model we've estimated.

```{r, message=FALSE, echo=FALSE, warning=FALSE, warn = FALSE}

nsa_prediction <- forecast(nsa_our_model, h = 20000, level=c(95))
nsa_ts.d  <- as.data.frame(yearmonth(as.yearmon(2020 + seq(0, 19999)/12)))
nsa_forecast_df <- cbind(nsa_ts.d, nsa_prediction)

colnames(nsa_forecast_df )[1] <- "time_index"
colnames(nsa_forecast_df )[2] <- "point_forecast"
colnames(nsa_forecast_df )[3] <- "lo_95"
colnames(nsa_forecast_df )[4] <- "high_95"

nsa_forecast_df = as_tsibble(nsa_forecast_df)
nsa_forecast420ppm <- nsa_forecast_df %>%
 filter(round(point_forecast,0) == 420 | round(lo_95,0) == 420 | round(high_95,0) == 420)
# max(nsa_forecast420ppm$time_index) - min(nsa_forecast420ppm$time_index) 

nsa_forecast500ppm <-nsa_forecast_df %>%
 filter(round(point_forecast,0) == 500 | round(lo_95,0) == 500 | round(high_95,0) == 500)

# max(nsa_forecast500ppm$time_index) - min(nsa_forecast500ppm$time_index) 

nsa_pe_420 = nsa_forecast_df %>%
 filter(round(point_forecast,0) == 420)
nsa_pe_500 = nsa_forecast_df %>%
 filter(round(point_forecast,0) == 500)

CO2_levels = c("420ppm", "500ppm")
first_low = c(min(nsa_forecast420ppm$time_index), min(nsa_forecast500ppm$time_index))
last_upper = c(max(nsa_forecast420ppm$time_index), max(nsa_forecast500ppm$time_index))
point_estimates = c(min(nsa_pe_420$time_index), min(nsa_pe_500$time_index))

fcst_display_df = data.frame(CO2_levels, first_low, point_estimates, last_upper)
fcst_display_df
```
From our observed forecasts above, it looks like the point estimates for when CO2 levels reach 420ppm is Mar 2022 while the theoretical `first time` and `last time` this model forecasts to be 420ppm is April 2021 and May 2606 respectively (according to our 95% confidence interval). Whereas, the point estimates for when CO2 levels reach 500ppm is April 2055, while the theoretical `first time` and `last time` this model would forecast 500ppm is May 2047 and May 2529 respectively. 

We'd also like to generate predictions of atmospheric CO2 levels for the year 2122:
```{r, message=FALSE, echo=FALSE, warning=FALSE, warn = FALSE}
nsa_forecast_df %>% filter_index("2122-01" ~ "2122-12")
```

### Closing remarks

According to the dataframe displayed above, according to the NSA model forecasts in the year 2122 we'd expect to see CO2 levels of 654ppm to around 660ppm. The 95% confidence intervals float around 550ppm for the low bound and 765ppm for the high bound. This is evidence of a very wide confidence interval. Observing these forecasted CO2 levels is quite daunting to be honest, as a team we were very surprised to find that in just 100 years, the CO2 levels could potentially rise by more than 100ppm.

It is interesting to note here that similar to the analysis done in the 1997 report, we have also estimate confidence intervals that are very wide. Based on this fact and combined with how this Keeling curve behaves, we conclude that we are not entirely confident our forecasts will accurate.
