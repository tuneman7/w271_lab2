---
output:
  pdf_document: default
  html_document: default
geometry: left=1cm,right=1cm,top=1cm,bottom=1.5cm
---

# Report from the Point of View of 1997 

## Introduction

In the 1950s, a geochemist, Charles David Keeling, began to collect air samples to measure the amount of carbon dioxide in the air, and these measurements would become his life's work. His initial samples indicated that the air contained more CO2 at night compared to the daytime. This finding suggested that plants absorbed CO2 during the day and released CO2 during the evening. Over time, his measurements showed a seasonal cycle, which was consistent with the seasonal patterns of terrestrial vegetation, and the CO2 data also would persistently increase over time. This rise in CO2 prompted questions about preconceived notions around the ocean's ability to absorb CO2 emitted by fossil fuels. If CO2 released by coal, natural gas, and petroleum remained in the air, this could account for the rise in CO2 over the years. 

This finding is incredibly important, because the rising rate of CO2 has implications on the Earth's ability to release heat from the atmosphere. If heat isn't able to escape, then this would subsequently result in a warmer climate, which would become known as the "greenhouse effect". However, while the CO2 data demonstrated a clear upward trend over time, it was also marked by periods of decline which could not solely be attributed to plant growth seasonality. A deeper investigation revealed that El Nino weather patterns affected the amount of CO2 that was released in the air by vegetation and soils. Over time, the data would also show earlier seasonal starts, and when this data was layered with temperature data, it had become clear that the concerns of a warming planet years earlier were starting to manifest itself within the data. Since this connection has been established between rising CO2 and corresponding global temperatures, more attention has surrounded the topics of global warming and climate change. As a result, business and political decision makers are starting to incorporate this data into their longer-term strategies; however, their pace of action may be too slow to prevent some of dangers associated with climate change. 

In the analysis below, we will confirm the trends identified above by Keeling himself and use this data to fit a model to make a forecast of CO2 levels in the future.

## Exploratory Data Analysis
```{r load packages, echo = FALSE, message = FALSE, warning=FALSE, warn = FALSE}
library(tidyverse)
library(tsibble)
library(latex2exp)
library(magrittr)
library(patchwork)
library(lubridate)
library(feasts)
library(forecast)
library(zoo)
library(fable)
library(sandwich)
library(lmtest)
library(tseries)
library(gridExtra)

theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```

The data that we will analyze in this report is monthly data on the CO2 levels made at the Mauna Loa observatory from Jan 1959 to Dec 1997. According to the data documentation, the air at Mauna Loa is thought to be representative of much of the Northern Hemisphere and potentially the globe as well, as the observatory is at an altitude of 3400 meters and surrounded by bare lava, which allows for measurement of "background" air that is resistent to day-to-day fluctuations in CO2 levels. 

The data is in units of "mole fraction", which according to the data source is "defined as the number of carbon dioxide molecules in a given number of molecules of air, after removal of water vapor. For example, 413 parts per million of CO2 (abbreviated as ppm) means that in every million molecules of (dry) air there are on average 413 CO2 molecules." The data that makes up our dataset was measured daily from Jan 1959 to Dec 1997, but in our dataset appears as an averaged mean per month in ppm units.

Let's take a look at the data. In raw form, it appears as a matrix of doubles that represent the ppm measurements per month and year combination, as appears below. Let's create some initial EDA plots that will allow us to better understand the data. Let's start by analyzing time series, histogram, auto-correlation function (ACF), and partial auto-correlation function (PACF) plots.

```{r echo = FALSE, message = FALSE}
co2_df <- tsibble::as_tsibble(co2)

plot <- co2_df %>%
  ggplot + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Monthly Mean $CO_2$)'),
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )
hist <- co2_df %>%
  ggplot(aes(x=value)) + geom_histogram(bins=8) + labs(title="Histogram")
acf <- ggAcf(co2_df$value, lag.max=(15*12)) + labs(title="ACF")
pacf <- ggPacf(co2_df$value, lag.max=(15*12)) + labs(title="PACF")

plot + acf + hist + pacf + plot_layout(design = "
AAAAACCCC
AAAAACCCC
BBBBBCCCC
BBBBBCCCC
DDDDDCCCC
DDDDDCCCC
")
```
As we can see above, the data seems to follow a clear and increasing trend, with a distinct seasonal pattern that appears as "waves" that we would like to further analyze. The magnitude of the fluctuations do not appear to vary with the time series level, so in terms of decomposition, an additive model would likely fit this series best. The time series does not appear stationary from this plot, as the mean does not appear constant and in fact appears to increase over time, but the variance appears to be constant.

The ACF starts out close to 1 and declines slowly over time, losing significance but staying mostly positive and above the significance line until around lag 140. This slow decline in ACF is what we should see in a time series with a pronounced trend effect, and tracks with what we noticed in the previous time series plot. There appear to be "waves" in the ACF plot similar to the "waves" we also noticed in the time series plot, indicating that the there is a seasonal or cyclic component to our data. Thinking ahead to our modeling, the ACF seems to indicate an autoregressive component in our data generating process, as it declines slowly over time.

The PACF starts out with a single significant positive spike at lag 1, followed by a (relatively smaller) significant negative spike at lag 2, with oscillating clusters of positive and negative lags with much lower levels of significance as the lag number increases. Thinking ahead to our modeling, the PACF seems to indicate an moving average component in our data generating process, as it oscillates between positive and negative over time.

The histogram shows that the CO2 values seem to range between 300 and 380 ppm and do not appear normally distributed, with most values in between these two ranges. 

Let's take a closer look at the seasonality in the data. We'll start by creating a season plot and a subseries plot of the data.

```{r echo = FALSE, message = FALSE, fig.width=5, fig.height=8}
seasons <- ggseasonplot(x = co2, year.labels=TRUE, year.labels.left=TRUE) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Seasonal plot: Monthly mean $CO_2$)'))

subseries <- ggsubseriesplot(x = co2) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Subseries plot: Monthly mean $CO_2$)'))

seasons + subseries + plot_layout(design = "
AAAAAA
AAAAAA
AAAAAA
BBBBBB
")
```

From these plots, we can see that the CO2 levels appear to increase from January through May, then decrease from June through October, hitting a low in October, and then increase again from November through end of the year. The source report does mention that plants and soil absorbing and emitting CO2 could influence these measurements. A possible explanation could be that, in the colder months, we can expect higher CO2 levels as plants die off, and in the warmer months, we can expect lower CO2 levels as plants thrive. Of course, there is variability across the Northern Hemisphere in what counts as "colder" months and when plants thrive - for example, Hawaiian "winter" is temperate and plants can grow year round, so this could explain why the seasonal variability is slight across the year. We can again see the trend of CO2 levels increasing year by year, but the seasonality effect seems constant year after year without a noticeable increase in the magnitude of the fluctuations across years, again supporting an additive model.

We can confirm that our time series trend is increasing by removing our seasonality components and aggregating our data by year instead of month, as seen below.

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=3, fig.height=3}
year_agg_plot <- co2_df %>%
  mutate(year = year(index)) %>%
  index_by(year) %>%
  summarise(avg_value = sum(value)) %>%
  ggplot(aes(x = year, y = avg_value)) +
  geom_line() +
  labs(title = TeX(r'(Annual Mean $CO_2$ Levels)'), y = TeX(r'($CO_2$ Parts per Million)'), x = "Year") 

year_agg_plot
```

We can also use both additive and multiplicative decomposition to remove both the trend and seasonal movements from our dataset and confirm that the variance is stationary. The results from these decompositions are plotted below.

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=7, fig.height=5}
co2_df <- co2_df %>%
  mutate(log_value = log(value))

dcmp_add <- co2_df %>%
  model(stl = STL(value))

dcmp_multi <- co2_df %>%
 model(stl = STL(log_value))

decomp <- components(dcmp_add) %>% autoplot()
residuals <- components(dcmp_add)%>%
  ACF(remainder) %>%
  autoplot() + labs(title="Additive residuals")
log_decomp <- components(dcmp_multi) %>% autoplot()
log_residuals <- components(dcmp_multi) %>%
  ACF(remainder) %>%
  autoplot() + labs(title="Multiplicative residuals")

grid.arrange(decomp, residuals, log_decomp, log_residuals, nrow = 2, ncol = 2)
```

From these plots, we can confirm again that the time series is trending upwards, as seen in the "trend" sections of the decomposition plots. However, upon closer look, the fluctuations within the seasonality of the time series seem to grow slightly larger over time, which we can see in the "season_year" section of the top left plot. In the multiplicative plot on the bottom left, the "season_year" plot appears just slightly more stable, tentatively supporting the idea that this might actually be a multiplicative time series, contrary to our earlier findings. In the next section we should take a look at applying a log transform on our series prior to modeling.

Looking at the residual plots, the residuals on both appear stationary, meaning that the decomposition methods we are using was able to eliminate deterministic components from the time series. However, they do not appear to be white noise, meaning that there is still correlation in the data.

Let's complete our EDA by running statistical tests to determine whether our model is stationary or non-stationary. We will run both the Augmented Dickey-Fuller (ADF) test and the Phillips Perron (PP) test to do this, under the following hypotheses:

H0: Time series is non-stationary

H1: Time series is stationary

```{r echo = FALSE, message = FALSE, warning = FALSE}
adf.test(co2, alternative="stationary", k=5)
pp.test(co2)
```
Based on the ADF and PP tests, we can reject the null hypothesis that the time series is non-stationary. This is surprising as from our visual analysis of the time series plots, the time series does not appear to be stationary as the mean trends upwards. Because we know that both the ADF and PP tests have low power, we will move forward with the assumption that this time series is non-stationary based on our visual EDA.

## Modeling

Let's start by creating two linear models, one fit on our CO2 data and one fit on the log transform of our CO2 data. Since in our EDA we did notice that the fluctuations within the seasonality of the time series seem to grow slightly larger over time, potentially indicating a multiplicative series, we want to try out this log transform to see if it reduces variance in our model and leads to smaller residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_linear <- co2_df %>%
  model(trend_model = TSLM(value ~ trend()))

fit_linear_log <- co2_df %>%
  model(trend_model = TSLM(log_value ~ trend()))

fit_linear %>% report()
fit_linear_log %>% report()
```

We can see from the output here that the R-squared values on both models are high and the input coefficients are highly significant on both. We will also plot the models on top of our data.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_linear_plot <- augment(fit_linear)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Linear Model / Mean $CO_2$ Levels)')) 

fit_linear_log_plot <- augment(fit_linear_log)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Log Linear Model / Log Mean $CO_2$ Levels)')) 

grid.arrange(fit_linear_plot, fit_linear_log_plot, nrow = 1, ncol = 2)
```
From these plots, both models seem to do a similar job fitting the data but fail to account for any of the seasonal "waves". Next, let's examine the model residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_linear %>% gg_tsresiduals() + labs(title = "Linear Residuals") 
fit_linear_log %>% gg_tsresiduals() + labs(title = "Log Linear Residuals") 
```
The residuals don't look much different here between the linear and log linear models, signaling that a log transformation is unnecessary for the linear model. In both models, the ACFs show a periodic oscillating pattern which signals that something is missing from our model. Based on our EDA, this is most likely the seasonality that we discussed but did not account for in this model. Additionally, the residuals appear somewhat normally distributed for both models. Let's run a Ljung Box test to understand whether we have white noise residuals, under the following hypotheses:

H0: Data are independently distributed.

H1: Data are not independently distributed.

```{r echo = FALSE, message = FALSE, warning = FALSE}
linear_residuals <- fit_linear %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

linear_log_residuals <- fit_linear_log %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

Box.test(linear_residuals, lag = 1, type = "Ljung-Box")
Box.test(linear_residuals, lag = 10, type = "Ljung-Box")
Box.test(linear_log_residuals, lag = 1, type = "Ljung-Box")
Box.test(linear_log_residuals, lag = 10, type = "Ljung-Box")
```

Based on the Ljung Box test, we can reject the null that the data is independently distributed up to 10 lags, which means that we likely do not have white noise residuals and both our models are failing to account for some variance in our data (likely the seasonality).

Let's repeat this process with a quadratic trend model.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic <- co2_df %>%
   model(trend_model = TSLM(value ~ trend()+I(trend()^2))) 
 
fit_quadratic_log <- co2_df %>%
   model(trend_model = TSLM(log_value ~ trend()+I(trend()^2))) 

fit_quadratic %>% report()
fit_quadratic_log %>% report()
```

We can see from the output here that the R-squared values on both models are high and the input coefficients are highly significant on both. We will also plot the models on top of our data.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_plot <- augment(fit_quadratic)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Quadratic Model / Mean $CO_2$ Levels)')) 

fit_quadratic_log_plot <- augment(fit_quadratic_log)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Log Quadratic Model / Log Mean $CO_2$ Levels)')) 

grid.arrange(fit_quadratic_plot, fit_quadratic_log_plot, nrow = 1, ncol = 2)
```

From these plots, both models seem to do a similar job fitting the data. Next, let's examine the model residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic %>% gg_tsresiduals() + labs(title = "Quadratic Residuals") 
fit_quadratic_log %>% gg_tsresiduals() + labs(title = "Log Quadratic Residuals") 
```

The residuals don't look much different here between both models, signaling that a log transformation is unnecessary for the quadratic model as well. In both models, the ACFs show the same periodic oscillating pattern which signals that the seasonality is likely missing from our model. The residuals also appear somewhat normally distributed for both models. Let's run a Ljung Box test again to understand whether we have white noise residuals under the same hypotheses as before:

```{r echo = FALSE, message = FALSE, warning = FALSE}
quadratic_residuals <- fit_quadratic %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

quadratic_log_residuals <- fit_quadratic_log %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

Box.test(quadratic_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_residuals, lag = 10, type = "Ljung-Box")
Box.test(quadratic_log_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_log_residuals, lag = 10, type = "Ljung-Box")
```

As before, based on the Ljung Box test, we can reject the null that the data is independently distributed up to 10 lags, which means that we likely do not have white noise residuals and both our models are failing to account for some variance in our data (likely again the seasonality).

Since the log transforms don't appear to reduce any of the variance in our models, I am going to compare the linear model directly with the quadratic model on non-transformed data. Our previous analysis shows that both models are behaving similarly but the quadratic model did have smaller residuals compared to the linear model, making it the more favorable model. In addition to the residual analysis, I going to compare the two using the Bayesian Information Criteria (BIC) as my metric.

```{r echo = FALSE, message = FALSE, warning = FALSE}
glance(fit_linear) %>% 
  select(BIC)

glance(fit_quadratic) %>% 
  select(BIC)
```

The quadratic model has a lower BIC, so I will move forward using the quadratic model. Our next step is to fit a polynomial model that incorporates seasonal dummy variables, which will hopefully account for some of the variance that we failed to capture in our previous models. We'll create models using both the log transform and the normal CO2 values, although it has appeared from our past models that the log transform does not seem to account for much, if any, variance in our data.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_season <- co2_df %>%
  model(trend_model = TSLM(value ~ trend() + I(trend()^2) + season())) 

fit_quadratic_log_season <- co2_df %>%
  model(trend_model = TSLM(log_value ~ trend() + I(trend()^2) + season())) 

fit_quadratic_season %>% report()
fit_quadratic_log_season %>% report()
```

Just from this summary, we can see that the R-squared values are slightly higher on both of these seasonal models than either the linear or quadratic models. We can also see that all the input coefficients are highly significant. Let's plot our models next.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_season_plot <- augment(fit_quadratic_season)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Quadratic Seasonal Model / Mean $CO_2$ Levels)')) 

fit_quadratic_log_season_plot <- augment(fit_quadratic_log_season)%>%
  ggplot(aes(x = index)) +
  geom_line(aes(y = log_value, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = "Time", title = TeX(r'(Log Quadratic Seasonal Model / Log Mean $CO_2$ Levels)')) 

grid.arrange(fit_quadratic_season_plot, fit_quadratic_log_season_plot, nrow = 1, ncol = 2)
```

From these plots, both models seem to do a similar job fitting the data and, unlike the previous models we've seen, actually account for the seasonal "waves" in our plot and track them pretty closely. Next, let's examine the model residuals.

```{r echo = FALSE, message = FALSE, warning = FALSE}
fit_quadratic_season %>% gg_tsresiduals() + labs(title = "Quadratic Season Residuals") 
fit_quadratic_log_season %>% gg_tsresiduals() + labs(title = "Log Quadratic Season Residuals") 
```

The residuals again don't look much different here between both models, signaling that a log transformation is unnecessary for this seasonal quadratic model as well. In both models, the ACFs now shows highly significant and slowly declining lags, unlike the ACF plots on the previous models which showed an oscillating trend that was likely related to seasonality variance that our latest models are now capturing. The residuals appear somewhat normally distributed for both models. In comparison to both the non-seasonal linear and quadratic models, the residuals are small in magnitude. Let's run a Ljung Box test again to understand whether we have white noise residuals under the same hypotheses as before:

```{r echo = FALSE, message = FALSE, warning = FALSE}
quadratic_season_residuals <- fit_quadratic_season %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

quadratic_log_season_residuals <- fit_quadratic_log_season %>%
  augment() %>%
  select(.resid) %>%
  as.ts()

Box.test(quadratic_season_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_season_residuals, lag = 10, type = "Ljung-Box")
Box.test(quadratic_log_season_residuals, lag = 1, type = "Ljung-Box")
Box.test(quadratic_log_season_residuals, lag = 10, type = "Ljung-Box")
```

As before, based on the Ljung Box test, we can reject the null that the data is independently distributed up to 10 lags, which means that we likely do not have white noise residuals and both our models are failing to account for some variance in our data. This is surprising as our residuals are quite small, especially in comparison to our previous models. Let's compare the BIC of the quadratic seasonal model without the log transform to our previous BICs.

Let's compare the BIC of this model against the pure linear and quadratic models without seasonal components.

```{r echo = FALSE, message = FALSE, warning = FALSE}
glance(fit_quadratic_season) %>% 
  select(BIC)
```

The BIC for our quadratic seasonal model is much smaller than the BICs for either our linear or quadratic model, and by this criteria is our best model that we have fit so far. Let's use this model to generate forecasts to the year 2020.

```{r echo = FALSE, message = FALSE, warning = FALSE}
future_df <- new_data(co2_df, n=23 * 12)

predictions <- fit_quadratic_season %>%
  forecast(new_data = future_df)

fit_quadratic_season %>%
  forecast(new_data = future_df) %>%
  autoplot(co2_df) + labs(title = "CO2 Predictions Using Seasonal Quadratic Model")
```

We can see that these predictions continue to follow the trend and seasonal fluctuations that we noticed in our data. Let's complete our linear modeling by examining the CLM assumptions for our best model, the seasonal quadratic model.

The first CLM assumption is that the underlying data generating process follows a linear model. We cannot check this assumption and will just assume it's true, or that we are just fitting the best linear model to the data if it is untrue.

The second assumption is ergodatic stationarity. Since this model is including trend and seasonal variables, we are eliminating the deterministic parts in the process and are satisfying this assumption. From the ACF plot, the process does look stationary but the residuals do appear serially correlated.

The third assumption is no perfect multicollinearity. When we fit our model, R did not report any warning or missing coefficients, which means that this assumption is violated.

The fourth assumption is the zero conditional mean assumption. We can evaluate this by looking at these residuals versus the fitted value plot, which appears below. If this assumption is satisfied, there should be no relationship between the fitted values and the residuals, a.k.a. there should be a straight line in the plot.

```{r echo = FALSE, message = FALSE, warning = FALSE}
augment(fit_quadratic_season) %>%
  ggplot(aes(x = .fitted, y = .innov)) +
  geom_point() +
  geom_smooth(se=FALSE)+
  scale_x_log10() +
  labs(title = "Seasonal Quadratic Model Residuals vs Fitted")
```

The line is curved, so we cannot justify that the zero conditional mean assumption is satisfied, meaning that there are likely additional variables that should be included in our model.

The fifth CLM assumption is homoskedasticity. The residuals are quite spread out with a large range of variance, so it seems as though this assumption cannot be satisfied.

The last assumption is no serial correlation. From our ACF plot, the residuals do appear to be serially correlated. Additionally, the Ljung Box test returns a high statistic with a small p-value. We can reject the null hypothesis that there is no autocorrelation and conclude that our residuals here are autocorrelated, thereby not satisfying this assumption.

The residuals do look close to a normal distribution, which gives us more confidence in our generated prediction intervals.

###ARIMA Modeling

Now, let's choose an ARIMA model to fit to the CO2 data. Recall that our EDA indicated that the CO2 data had the following characteristics: * non-stationary data series, 
* slowly decaying ACF plot, indicative of an AR process
* oscillating PCAF plot, indicative of an MA process
* seasonal data

In order to transform the data into a stationary series, we can start by applying a first-order difference to the series. 

```{r}

#first-order difference
first_diff <- co2_df %>%
  mutate(diff_co2 = difference(value)) 

co2_df %>%
gg_tsdisplay(difference(value),
               plot_type='partial', lag=36) +
  labs(title="First-order differenced", y="")
```
Based on the trend plot, the data seems to stabilize around a mean of -0.5, and it appears to have a constant variance, suggesting that the data only needs a first-order difference. The ACF plot continues to decay gradually but the oscillating behavior persists here. This indicates that the seasonal pattern is strong and stable after a first-order difference. As a result, we will want to use a seasonal difference in addition to this first difference. Since the seasonal behavior repeats every year, we will set m = 12, meaning the seasonal pattern repeats once every twelve months.

```{r}
#seasonally differenced
co2_s_diff <- co2_df %>%
  mutate(sdiff_co2 = difference(value, 12)) 

co2_s_diff

#plots for seasonal differencing
co2_df  %>%
gg_tsdisplay(difference(value, 12),
               plot_type='partial', lag=36) +
  labs(title="Seasonally differenced", y="")

```

On its own, seasonal differencing does not appear to make the data stationary. However, based on the ACF plot, we can confirm that the seasonal differencing either removes or significantly reduces the oscillation as it does not seem apparent anymore. As a result, we can conclude that we need both a first difference and a seasonal difference on the series. We can confirm these observations using the following unit root tests. We will first use the  Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test under the following hypothesis:

H0: The data are stationary
HA: The data are not stationary

```{r}
#unit root tests

co2_df %>%
  features(value, unitroot_kpss)

first_diff %>%
  features(diff_co2, unitroot_kpss)

co2_s_diff %>%
  features(sdiff_co2, unitroot_kpss )

```

We can interpret the tests in the following manner:
* For the undifferenced data, the test statistic (7.81) is bigger than the 1% critical value, so the p-value is less than 0.01, indicating that the null hypothesis is rejected. That is, the data are not stationary.
* For the first differenced data, the p-value is greater than 0.1, indicating the test fails to reject the null hypothesis. That is, the data are stationary.
* For the seasonally differenced data, the test statistic (1.94) is bigger than the 1% critical value, so the p-value is less than 0.01, indicating that the null hypothesis is rejected. That is, the data are not stationary.
Thus, we can conclude that we need both a first difference and a seasonal difference. But, how many differences do we need? To confirm that we are applying the appropriate amount of differences, we can use the following:

```{r}

#confirm the number of differences needed in the data
co2_df %>%
  features(value, unitroot_ndiffs)

first_diff %>%
  features(diff_co2, unitroot_ndiffs)

co2_s_diff %>%
  features(sdiff_co2, unitroot_ndiffs)

#test need for seasonal differencing; indicating one seasonal difference is required

co2_df %>%
  features(value, unitroot_nsdiffs)

first_diff %>%
  features(diff_co2, unitroot_nsdiffs)

co2_s_diff %>%
  features(sdiff_co2, unitroot_nsdiffs)
```

Here we can see that once we apply a first difference and a seasonal difference, the test returns 0, indicating no additional differences are required. It is important that we correctly identify the correct number of differences as we could potentially introduce false dynamics or autocorrelations into the time series.

```{r}
#double differenced
co2_df %>%
  gg_tsdisplay(difference(value, 12) %>% difference(),
               plot_type='partial', lag=36) +
  labs(title = "Double differenced", y="")
```
We will now use the ACF and PACF plots of our double differenced data to determine an appropriate ARIMA model via brute force. The significant spike at lag 3 in the ACF suggests a non-seasonal MA(3) component. The significant spike at lag 12 in the ACF suggests a seasonal MA(1) component. So, we might begin with an ARIMA(0,1,3)(0,1,1)12 model, indicating a first difference, a seasonal difference, and non-seasonal MA(3) and seasonal MA(1) component. 

```{r}
fit1 <- arima(co2_df$value, order = c(0,1,3), seasonal= list(order = c(0,1,1), period = 12))

#fit1 <- co2_df %>%
#  model(
#  arima_fit = ARIMA(value~0+pdq(0,1,3)+PDQ(0,1,1, period=12)),
#  ) 
fit1
```

```{r}
resid <- residuals(fit1)
autoplot(resid)
ggAcf(resid)

Box.test(resid, lag=10, fitdf=0, type="Lj")
```
The ACF plot indicates that the residuals are following a white noise process as each autocorrelation is close to zero and 95% of spikes lie within significance thresholds. There is one small but significant spike at lag 9. Additionally, since the p-value from the Box-Ljung test is greater than 0.05, we fail to reject the null hypothesis and conclude that there is no serial correlation in the data.

If we had evaluated the PACF as well, we may have chosen ARIMA(3,1,0)(1,1,1)12 model, indicating a first difference, a seasonal difference, non-seasonal AR(3) and MA(1) components, and seasonal AR(1) and AR(1) component. The significant spike at lag 3 in the PACF suggests a non-seasonal AR(3) component. The significant spike at lag 12 in the PACF suggests a seasonal AR(1) component. However, by comparing the AIC values of the first and second model, the first selection was a better fit based on the lower AIC value.

```{r}
fit2 <- arima(co2_df$value, order = c(3,1,1), seasonal= list(order = c(1,1,1), period = 12))
fit2
```

We can also try automatically fitting the model with the following code:
```{r}
#documentation seems outdated
#source_1:https://otexts.com/fpp2/seasonal-arima.html
#source_2:https://campus.datacamp.com/courses/forecasting-in-r/forecasting-with-arima-models?ex=10

auto_fit <- co2_df %>% model(ARIMA(value)) %>%  report()

```


```{r}
auto_fit %>% 
  gg_tsresiduals(lag=36) 


auto_resid <- residuals(auto_fit)
auto_resid
Box.test(auto_resid[3] ,lag=10, fitdf=0, type="Lj")

```
The trend and ACF plots indicate that the residuals of the automatically fitted ARIMA model are following a white noise process. Autocorrelations are close to zero and 95% of spikes lie within significance thresholds. There is one small but significant spike at lag 9. Also, since the p-value from the Box-Ljung test is greater than 0.05, we fail to reject the null hypothesis and conclude that there is no serial correlation in the data. However, the automatically fitted ARIMA model does not outperform our first guess as the AIC in `r auto_fit` is higher. We will continue to proceed with the ARIMA(0,1,3)(0,1,1)12.

```{r}
future_d <- new_data(co2_df, n=25 * 12)

co2_df %>%
  model(ARIMA(value ~ 0 + pdq(0,1,3) + PDQ(0,1,1))) %>%
  forecast(new_data = future_d) %>%
  autoplot(co2_df ) +
  labs(x = 'Month of Year',
    y="CO2 (PPM)",
       title="CO2 measurements over time")

```

Again, we can see that these predictions continue to follow the trend and seasonal fluctuations that we noticed earlier in the data. However, our confidence intervals continue to widen with each year that we forecast. 

###Forecast atmospheric CO2 growth

If we generate predictions for when atmospheric CO2 is expected to be at 420 ppm and 500 ppm levels at the 95% confidence level, we can observe the wide confidence intervals noted in the previous graph. Predictions for 420ppm were as early as April 2022 and as late as December 2100. Surprisingly, when we make predictions on for 500ppm the confidence intervals narrow. According to this model's predictions, 500ppm CO2 levels will occur as early as March 2055 and as late as August 2086.

```{r}
co2_ext_forecast <- forecast(fit1, h=103 * 12, level = c(95))
co2_ext_forecast <- summary(co2_ext_forecast)

ts.d  <- as.data.frame(as.yearmon(1998 + seq(0, 1235)/12))

forecast_df <- cbind(ts.d, co2_ext_forecast)
colnames(forecast_df )[1] <- "time_index"
colnames(forecast_df )[2] <- "point_forecast"
colnames(forecast_df )[3] <- "lo_95"
colnames(forecast_df )[4] <- "high_95"

forecast420ppm <- forecast_df %>%
 filter(round(point_forecast,0) == 420 | round(lo_95,0) == 420 | round(high_95,0) == 420)

min(forecast420ppm$time_index) 
max(forecast420ppm$time_index)

max(forecast420ppm$time_index) - min(forecast420ppm$time_index) 

forecast500ppm <-forecast_df %>%
 filter(round(point_forecast,0) == 500 | round(lo_95,0) == 500 | round(high_95,0) == 500)

min(forecast500ppm$time_index) 
max(forecast500ppm$time_index)

max(forecast500ppm$time_index) - min(forecast500ppm$time_index) 

forecast500ppm <-forecast_df %>%
 filter(round(point_forecast,0) == 500 | round(lo_95,0) == 500 | round(high_95,0) == 500)
```

When we look specifically at CO2 levels in 2100, we can expect the ppm values to be around 525 throughout the course of the year with fairly wide confidence intervals about 100ppms lower or higher. 

```{r}
sapply(forecast_df, class)

forecast_df %>%
 filter(year(time_index)==2100)

forecast_df %>%
 filter(year(time_index)==2100)%>%
  ggplot(aes(time_index, point_forecast)) + geom_point() + 
  geom_errorbar(aes(ymin = lo_95, ymax = high_95)) +
  labs(x = 'Month of Year',
    y="CO2 (PPM)",
       title="2100 CO2 predictions")
```
Based on the very wide confidence intervals, we're not very confident that these are accurate predictions. To assess the accuracy of our predictions more methodically, we can create a training set and a test set. From the plot, we can see that our predictions widen from the actuals with each consecutive year in just the last 8 years. While our predictions are probably a best guess given the information that we have, the ARIMA model assumes that seasonality is fixed over time, and this may be a strong assumption to make given that there are other factors that could likely impact CO2 over time. 

When we observe the residuals, we also notice that there are two significant spikes in the ACF plot at lag 3 and lag 9. Our p-value from the Box-Ljung test is also greater than 0.05, meaning that we fail to reject the null hypothesis of no serial correlation. However, since both of these observations are close to the significance threshold, this may be cause for concern around the predictive power of our model, particularly for such a far projection in time. 

```{r}
#https://robjhyndman.com/hyndsight/longseasonality/
#https://otexts.com/fpp3/tscv.html

#creating training data
train <- co2_df %>% filter_index(. ~ "1989 Jan")
train

fit_arima <- train %>% model(ARIMA(value))
report(fit_arima)

co2_fc <- fit_arima %>%
  forecast(h = 12 *8)

co2_fc  %>%
  autoplot(
    co2_df %>% filter(year(index) >= 1989),
    level = NULL
  ) +
  labs(
    y = "CO2 (ppm)",
    title = "Forecasts for co2 levels"
  ) +
  guides(colour = guide_legend(title = "Forecast"))

fit_arima %>% 
  gg_tsresiduals(lag_max = 16)

augment(fit_arima) %>%
  features(.innov, ljung_box, lag = 16, dof = 6)

```



# PRESENT
```{r load packages, echo = FALSE, message = FALSE, warning=FALSE}

list.of.packages <- c("latex2exp")


new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(tidyverse)
library(tsibble)
library(latex2exp)
library(magrittr)
library(patchwork)
library(lubridate)
library(feasts)
library(forecast)
library(zoo)
library(fable)
library(sandwich)
library(lmtest)
library(tseries)
library(gridExtra)

theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```

## (1 point) Task 0b: Introduction 

We now ask the question of whether the data collected from January 1998 to the present has different characteristics which could lead us to additional or different conclusions than those which the dataset from 1958 until 1997 yielded.

We assume that the collection process for both datasets is identical.

It is worth noting that the "present" dataset contains only about 24 years, or 293 months, compared to the 39 years, or 468 months contained in the "1997" dataset.


## (3 points) Task 1b: Create a modern data pipeline for Mona Loa CO2 data.

As instructed we pulled created a pipeline to pull down the weekly Mona Loa CO2 data.

Within the dataset the weeks ending on dates; 2008-06-29, 2008-07-06 , 2008-07-13 , 2005-10-16, contained the measurement value -999.99, which cannot be accurate.  We "stubbed" those four dates with values similar to the weekly values for the weeks directly before or after.  We did not remove those data outright as doing so could cause problems within the utilization of the timeseries downstream.  


```{r echo = FALSE, message = FALSE, warming=FALSE}

#Create a data pipeline that starts by reading from the appropriate URL, and ends by saving an object called `co2_present` that is a suitable time series object. #load from National Oceanic and Atmospheric Web site.
#filter, mutate, and turn into tsibble object

#Grab Monthly Data -- May not use this.
co2_present_monthly <- read.table('https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt') %>%
  filter(V1 >= 1998)%>%
  mutate(index = yearmonth(as.yearmon(paste(V1, V2), "%Y %m"))) %>%
  mutate(value = V4) %>%
  mutate(log_value = log(V4)) %>% 
  dplyr::select(c("index","value","log_value")) %>%
  as_tsibble(index=index)

#In Examining this data there are two perios where collections are incorrect on a weekly basis.
# 1.  Period 
#545 2008-06-08 387.74 5.960335
#546 2008-06-15 388.11 5.961289
#547 2008-06-22 387.53 5.959793
#548 2008-06-29 -999.99 NaN
#549 2008-07-06 -999.99 NaN
#550 2008-07-13 -999.99 NaN
#    2005-10-16 -999.99 NaN
#
#Grab weekly data
co2_present <- read.table('https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.txt') %>%
  filter(V1 >= 1998)%>%
  mutate(index = as.Date(as.Date(paste(V1,V2,V3, sep="-")) )) %>%
  mutate(value = V5) %>%
  filter(value > 200) %>%
  mutate(log_value = log(value)) %>% 
  dplyr::select(c("index","value","log_value"))
  

#dates I'm manually putting values in.
index <- as.Date(c('2008-06-29','2008-07-06','2008-07-13','2005-10-16'))
value <- c(387.74,388.11,387.53,377.5)
log_value <- log(value)
df_insert <- data.frame(index,value,log_value)

co2_present <- bind_rows(
  co2_present,
  df_insert
) %>% as_tsibble(index=index)

#Aggregate the weekly to monthly
co2_present_weekly_agg_monthly <- as.data.frame(co2_present) %>%
  filter(year(index) >= 1998)%>%
  mutate(index = yearmonth(index)) %>%
  group_by(index)  %>% 
  summarize(value=mean(value))  %>% 
  mutate(log_value = log(value)) %>% 
  dplyr::select(c("index","value","log_value")) %>%
  as_tsibble(index=index)

```


```{r echo = FALSE, message = FALSE}

#old data
co2_ts <- tsibble::as_tsibble(co2) %>%
  mutate(log_value = log(value))

plot_1997 <- co2_ts %>%
  ggplot + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Monthly Mean $CO_2$ 1958 through 1997)'),
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

hist_1997 <- co2_ts %>%
  ggplot(aes(x=value)) + geom_histogram(bins=8) + labs(title="Histogram 1958 through 1997")
acf_1997 <- ggAcf(co2_ts$value, lag.max=(15*12)) + labs(title="ACF 1958 through 1997")
pacf_1997 <- ggPacf(co2_ts$value, lag.max=(15*12)) + labs(title="PACF 1958 through 1997")


plot_present <- co2_present %>%
  ggplot + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Weekly Mean $CO_2$)'),
    subtitle = " 1998 through Present",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )
hist_present <- co2_present %>%
  ggplot(aes(x=value)) + geom_histogram(bins=8) + labs(title="Histogram 1998 through Present")
acf_present <- ggAcf(co2_present$value, lag.max=(15*12)) + labs(title="ACF 1998 through Present")
pacf_present <- ggPacf(co2_present$value, lag.max=(15*12)) + labs(title="PACF 1998 through Present")
#acf_present
#pacf_present
plot_present + acf_present + hist_present + pacf_present + plot_layout(design = "
AAAAACCCC
AAAAACCCC
BBBBBCCCC
BBBBBCCCC
DDDDDCCCC
DDDDDCCCC
")



```

As with the "1997" dataset, we see a clear increasing trend with the same seasonal "wave" pattern.  Seasonal fluctuation does not appear to increase with time, suggesting, again, that an additive model explains the decomposition in this series.  The time series is not stationary, as its mean increases.  Variance presents as constant.

The ACF displays a slow, over-time, decline consistent with a trending time series.  While the ACF plot of the "1997" plot remains above the significance line until lag 140, this ACF plot never crosses the significance line.  

The PACF of this time series has a strong postive spike a lag 1 followed by a pattern consistant with partial autocorrelation.

Our histogram of has no values lower than 365, or nigher than 421, and that these values are not normally distributed.

In order to better understand the differences between these two datasets we examine them side by side.

```{r echo = FALSE, message = FALSE}

plot_present + plot_1997 + hist_present + hist_1997 + plot_layout(design = "
AAAAACCCC
AAAAACCCC
BBBBBDDDD
BBBBBDDDD
")

```

When we start looking graphing the two datasets side by side, the difference of one containing 39 years, and the other 24, begins to hamper our understanding.

We take only the last 293 months of the "1997" dataset and graph it on the same space as the "present" dataset.

```{r echo = FALSE, message = FALSE}


co2_df_1 <-
  co2_ts %>%
  mutate(id = row_number())  %>%
  filter(id > 175) %>%
  mutate(id = row_number()) %>%
  dplyr::select("id","value")  %>%
  as_tsibble()
  #dplyr::select("id","1972 through 1997")

co2_present_df <-
  as.data.frame(co2_present_weekly_agg_monthly) %>%
  mutate(id = row_number()) %>%
  #mutate("1997 through present"=value) %>%
  dplyr::select("id","value")

min_1997 = min(co2_df_1[,2], na.rm=T)
min_present = min(co2_present_df[,2], na.rm=T)

max_1997 = max(co2_df_1[,2], na.rm=T)
max_present = max(co2_present_df[,2], na.rm=T)

delta_1997 = max_1997 - min_1997
delta_present = max_present - min_present

delta_between_periods = delta_present - delta_1997



ochart_1 <- ggplot() +
   geom_line(data=co2_df_1,
             aes(x=id,y=value, color="1973 through 1997"),
             size=1.2) +
   geom_line(data=co2_present_df,
             aes(x=id,y=value, color="1997 through present"),
             size=1.2) +
  labs(x = "Months",
       y = TeX(r'($CO_2$ parts per million)'),
       title="293 month comparison: 1973 through 1997, and 1998 through present.") +
     scale_color_manual(name='Periods',
                     breaks=c('1973 through 1997', '1997 through present'),
                     values=c('1973 through 1997'= '#ebcc34' , 
                              '1997 through present'='#eb3434'))
ochart_1



```

In the 293 months prior to Dec 31, 1997, the atmospheric CO2 rose by `r delta_1997` PPM.  By comparison, in the 293 months prior to May 31, 2022 (the most recent month we have a measurement for), the atmospheric CO2 rose by `r delta_present` PPM.  This is a difference of `r delta_between_periods` PPM during the same time interval.  This could indicate an acceleration in the increase in PPM.

We apply the same "parsing" of the original "1997" dataset and compare the parsed dataset's ACF and PACF graphs to those of the "present" dataset.

```{r echo = FALSE, message = FALSE}

acf_1997 <- ggAcf(co2_df_1$value, lag.max=(15*12)) + labs(title="ACF (monthly avg) 1973 to 1997")
pacf_1997 <- ggPacf(co2_df_1$value, lag.max=(15*12)) + labs(title="PACF (monthly avg) 1973 to 1997")

   (acf_1997 | acf_present + labs(title="ACF (weekly avg) 1998 to Present")) /
   (pacf_1997 | pacf_present + labs(title="PACF (weekly avg) 1998 to Present"))  +
  plot_annotation(
      title    = 'ACF and PACF comparison',
    #  subtitle = 'Could be Random Walk',
      tag_levels = 'A')  

```
Parsing the "1997" dataset, to include 293 months only, yields a ACF which crosses the significance line 100, while the weekly data does not cross the significance line.  We notice that the amplitude of oscillation on the "1997" datasets' ACF, is greater than the amplitude of oscillation in the "present" dataset's ACF.

Next we examine the seasonality of the "present" comparing it to the "1997" seasonality.

In order to the present dataset's seasonality 1997 seasonality we aggregate values within the weekly dataset to monthly values, for the purpose of this comparison.

```{r echo = FALSE, message = FALSE, fig.width=6, fig.height=5, warning=FALSE}

df_3_year_season_org <- co2_ts %>%
  filter(year(index)>= 1993)%>%
  select("index","value")

co2_present_no_log <- co2_present_weekly_agg_monthly %>%
  filter(year(index)>= 2017)%>%
  select("index","value")

combined_no_log_latest <- bind_rows(
  df_3_year_season_org,  
  co2_present_no_log
)

seasons_present <- ggseasonplot(x = as.ts(combined_no_log_latest), year.labels=TRUE, year.labels.left=TRUE) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Seasonal plot: Monthly mean $CO_2$)'))


seasons_present

```

In the plot above we look at the last 5 years in the "1997" dataset and the last 5 years of the "present" dataset.  

What we are trying to ascertain is if the seasonality has become more extreme.  It is difficult to ascertain if the seasonality has become more extreme based on the graph above.  

We next compare the two subseries graphs looking at each dataset.


```{r echo = FALSE, message = FALSE, fig.width=6, fig.height=4, warning=FALSE}

co2_df_1_ts <-
  co2_ts %>%
  mutate(id = row_number())  %>%
  filter(id > 175) %>%
  mutate(id = row_number()) %>%
  dplyr::select("index","value")  %>%
  as_tsibble()

subseries_1997 <- ggsubseriesplot(x = as.ts(co2_df_1_ts)) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Subseries plot: Monthly mean $CO_2$ 1973 through 1997)'))

subseries_present <- ggsubseriesplot(x = as.ts(co2_present_no_log)) +
  ylab(TeX(r'($CO_2$ Parts per Million)')) +
  ggtitle(TeX(r'(Subseries plot: Monthly mean $CO_2$ 1998 through 2022)'))


subseries_1997 + subseries_present + plot_layout(design = "
AAAAA
BBBBB
")


```

With this new plot it becomes clearer that the yearly oscillations in PPM are more extreme in the present dataset than in the one ending in 1997.

That is to say the seasonality effect shows a noticeable increase in the magnitude of the fluctuations in the second dataset.

We now remove the seasonal fluctuations in both datasets and graph the increase in atmospheric CO2 PPM.

In order to do this we aggregate our weekly data to monthly data in order to compare on the same scales.

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=6, fig.height=3}

co2_df_1 <-
  co2_ts %>%
  mutate(id = row_number())  %>%
  filter(id > 175) %>%
  mutate(year = year(index))  %>%
  index_by(year) %>%
  summarise(avg_value = (sum(value)/12)) %>%  
  mutate(id = row_number()) %>%
  filter(id > 1 ) %>%  
  dplyr::select("id","avg_value")
  #dplyr::select("id","1972 through 1997")

co2_present_df <- co2_present_weekly_agg_monthly %>%
  mutate(year = year(index))  %>%
  index_by(year) %>%
  summarise(avg_value = (sum(value)/12)) %>%  
  mutate(id = row_number())  %>%
  filter(id <= 24) %>%  
  dplyr::select("id","avg_value")


ochart_2 <- ggplot() +
   geom_line(data=co2_df_1,
             aes(x=id,y=avg_value, color="1973 through 1997"),
             size=1.2) +
   geom_line(data=co2_present_df,
             aes(x=id,y=avg_value, color="1997 through present"),
             size=1.2) +
  labs(x = "Months",
       y = TeX(r'($CO_2$ parts per million)'),
       title="293 month comparison: 1973 through 1997, and 1998 through present.",
       subtitle = "Smoothed") +
     scale_color_manual(name='Periods',
                     breaks=c('1973 through 1997', '1997 through present'),
                     values=c('1973 through 1997'= '#ebcc34' , 
                              '1997 through present'='#eb3434'))
ochart_2


```


We now perform additive and multiplicative decomposition to remove the trend and seasonal movements from our dataset to confirm that the 


```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=7.5, fig.height=6}
co2_present_monthly <- co2_present %>%
  mutate(log_value = log(value))

dcmp_add <- co2_present %>%
  model(stl = STL(value))

dcmp_multi <- co2_present %>%
 model(stl = STL(log_value))

decomp <- components(dcmp_add) %>% autoplot()
residuals <- components(dcmp_add)%>%
  ACF(remainder) %>%
  autoplot() + labs(title="Additive residuals")
log_decomp <- components(dcmp_multi) %>% autoplot()
log_residuals <- components(dcmp_multi) %>%
  ACF(remainder) %>%
  autoplot() + labs(title="Multiplicative residuals")

grid.arrange(decomp, residuals, log_decomp, log_residuals, nrow = 2, ncol = 2)
```

These graphs confirm that the time series is trending upwards.  In the additive decomposition plots (top left), we see that seasonal fluctuations increase over time.  This confirms our side-by-side graph above showing the increase in seasonal fluctuations between the two time series.

The multiplicative "season_year" decomposition graph is stable, and not visibly increasing.  This means like the "1997" time series, the "present" time series may be multiplicative.

Both residuals plots, again, show our time series as stationary, but not white noise.  This means correlation in the data still exists.

Next we run the ADF test, as well as the PP test to see if the time series is stationary.

H0: The data are not stationary
HA: The data are stationary

```{r echo = FALSE, message = FALSE, warning = FALSE}

co2_present_ts = as.ts(co2_present$value)

adf.test(co2_present_ts, alternative="stationary", k=5)
pp.test(co2_present_ts)


```

The tests above indicate that we can reject the null hypothesis that the time series is non-stationary.

The Unit Root tests above indicate that this time series is difference stationary.  

This contradicts our visual EDA, which shows a changing mean, given the strong upward trend.  

We should note that the tests above are testing whether the time series are difference stationary.  We apply a linear model and then graph its residuals.

```{r echo = FALSE, message = FALSE}
library(lmtest)

trModel <- lm(co2_present_ts ~ c(1:length(co2_present_ts)))

checkresiduals(trModel) 

```

Graphing the residuals appears to show a mean reverting process.  That is to say the residuals are stationary and not trending, and appear to be normally distributed.

Finally, we run an ADF and PP test on the residuals, and we again, see that the null hypothesis of non-trend-stationary can be ignored.

#Todo -- add note that there is seasonality in here.

H0: The data are not stationary
HA: The data are stationary


```{r echo = FALSE, message = FALSE}

adf.test(trModel$residuals, alternative="stationary", k=5)
pp.test(trModel$residuals, alternative="stationary")

```

Despite the fact that the ADF and PP tests indicate the data series is stationary, our visual analysis of this data set suggests that it is non-stationary as its mean is increasing over time.  We will ignore the ADF and PP test results as they can sometimes be of low power.

## (1 point) Task 2b: Compare linear model forecasts against realized CO2

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=6, fig.height=6}

future_df <- new_data(co2_ts, n=23 * 12)

fit_quadratic <- co2_ts %>%
   model(trend_model = TSLM(value ~ trend()+I(trend()^2))) 

fit_quadratic_season <- co2_ts %>%
  model(trend_model = TSLM(value ~ trend() + I(trend()^2) + season())) 

lm_prediction_based_on_1997_data <- fit_quadratic_season %>%
  forecast(new_data = future_df) %>%
  autoplot() +  
  labs(
    title = TeX(r'(Predicted Monthly Mean $CO_2$)'),
    subtitle = "Quadratic Model w/ Trend & Seasonal Effects",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

data_and_lm_prediction_overlay <- fit_quadratic_season %>%
  forecast(new_data = future_df) %>%
  autoplot(co2_present) +  
  labs(
    title = TeX(r'(Weekly Mean $CO_2$)'),
    subtitle = "(Series, with Linear Prediction Overlay)",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

(plot_present | lm_prediction_based_on_1997_data) /
  data_and_lm_prediction_overlay

```

In the top-left, we plot the 1998-present time series, next to it, we plot the prediction yielded by the best-fitting linear model we developed against the "1997" data set.  Beneath the two plots we overlay the original time series with the prediction.  Towards the middle of time time series, the fit is nearly perfect.  At both the beginning and end of the time series, there are barely visible differences the prediction and the "real" underlying time series.  

We predict 23 years from Dec 31, 1997, which means the predict values are through December 31 2021.  Our "present" time series contains data "through" May 2022, which means we have an addition 5 months of data, indicated by the solid black line extending upwards out of the prediction.

The linear model is very accurate.

## (1 point) Task 3b: Compare ARIMA models forecasts against realized CO2  




```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=6, fig.height=6}


future_d <- new_data(co2_ts, n=23 * 12)

data_and_arima_prediction_overlay <- co2_ts %>%
  model(ARIMA(value ~ 0 + pdq(0,1,3) + PDQ(0,1,1))) %>%
  forecast(new_data = future_d) %>%
  autoplot(co2_present)  +
  labs(
    title = TeX(r'(Weekly Mean $CO_2$)'),
    subtitle = "(Series, with ARIMA Prediction Overlay)",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

arima_prediction_based_on_1997_data<-co2_ts %>%
  model(ARIMA(value ~ 0 + pdq(0,1,3) + PDQ(0,1,1))) %>%
  forecast(new_data = future_d) %>%
  autoplot() +  
  labs(
    title = TeX(r'(Predicted Monthly Mean $CO_2$)'),
    subtitle = "(ARIMA Model w/ Trend & Seasonal Effects)",
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

(plot_present | arima_prediction_based_on_1997_data) /
  data_and_arima_prediction_overlay
#plot_present
#arima_prediction_based_on_1997_data
#data_and_arima_prediction_overlay

```
In the top-left, we plot the 1998-present time series, next to it, we plot the prediction yielded by the best-fitting ARIMA model we developed against the "1997" data set.  Beneath the two plots we overlay the original time series with the prediction.  The overlay shows a divergence between predicted ARIMA values and the actual trend.  

We predict 23 years from Dec 31, 1997, which means the predict values are through December 31 2021.  Our "present" time series contains data "through" May 2022, which means we have an addition 5 months of data, indicated by the solid black line extending upwards out of the prediction.

The linear model does not predict as accurately as the linear model.

To demonstrate this we graph both on top of one another below.


```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=6, fig.height=6}

data_and_lm_prediction_overlay / 
  data_and_arima_prediction_overlay

```   
## Evaluate the performance of 1997 linear and ARIMA models

In 1997 you made predictions about the first time that CO2 would cross 420 ppm. How close were your
models to the truth?
After reflecting on your performance on this threshold-prediction task, continue to use the weekly data to
generate a month-average series from 1997 to the present, and compare the overall forecasting performance
of your models from Parts 2a and 3b over the entire period. (You should conduct formal tests for this task.)

```{r, message=FALSE, echo=FALSE}
# display TS for atmospheric co2 for when we crossed 420ppm
# suggests 2022-04-25, different from forecasted april 2022 from 1997 and was not within our interval of April 2022 - December 2100
head(co2_present %>% filter(value>=420))

# aggregation
co2_present_weekly_agg_monthly <- as.data.frame(co2_present) %>%
  filter(year(index) >= 1998)%>%
  mutate(index = yearmonth(index)) %>%
  group_by(index)  %>%
  summarize(value=mean(value))  %>%
  mutate(log_value = log(value)) %>%
  dplyr::select(c("index","value","log_value")) %>%
  as_tsibble(index=index)

```

````{r, message=FALSE, echo=FALSE, warning=FALSE}
# model chosen form 2a

forecast420ppm <- forecast_df %>%
 filter(round(point_forecast,0) == 420 | round(lo_95,0) == 420 | round(high_95,0) == 420)

min(forecast420ppm$time_index) 
max(forecast420ppm$time_index)


fit_linear_2a = fit_linear
predictions_2a <- forecast(fit_linear, h = 1000)
accuracy_lm = accuracy(predictions_2a, co2_present_weekly_agg_monthly)
accuracy_lm
pe_420 = predictions_2a %>% filter(.mean>420)
pe_420 = pe_420[index= min(index)]
```

````{r,message=FALSE, echo=FALSE, warning=FALSE}
# first fit model 3a

fit1 <- co2_df %>%
  model(
  arima_fit = ARIMA(value~0+pdq(0,1,3)+PDQ(0,1,1, period=12)),
  )

fit_3a = fit1
predictions_3a_pf <- forecast(fit_3a, h=25*12, level=c(95))

accuracy_arima = accuracy(predictions_3a_pf, co2_present_weekly_agg_monthly)
accuracy_arima
```

## ARIMA modeling

Let's choose an ARIMA model to fit the present CO2 data from NOAA. First we will assess two datasets and two models, one dataset for seasonally adjusted data (SA) and one for non-sesonally adjusted data (NSA). Then, within both datasets, we will split the data into test and train sets with the last two years of data being the test set. Following the report from 1997 and observing the time series we have for our 1998-present data of $CO_2$ we will conclude with also applying linear differencing methods to our time series.

```{r, message=FALSE, echo=FALSE, warning=FALSE}

sa_co2_present_test <- co2_present_weekly_agg_monthly %>%
  filter(index>=as.Date("2020-01-01")) %>%
  model(stl = STL(value)) %>% 
  components()
sa_co2_present_train <- co2_present_weekly_agg_monthly %>%
  filter(index < as.Date("2020-01-01")) %>%
  model(stl = STL(value)) %>% 
  components()


nsa_co2_present_test <- co2_present_weekly_agg_monthly %>%
  filter(index>=as.Date("2020-01-01"))
nsa_co2_present_train <- co2_present_weekly_agg_monthly %>%
  filter(index < as.Date("2020-01-01"))

```

### Seasonally adjusted data assessment

Now that we have all of our necessary data, let's get to creating models for both. First let's assess the number of differences needed for the seasonally adjusted data to be stationary, since this data already has the season component stripped out, we know there are no seasonal differences needed. Let's also assess the acf and pacf.

```{r, echo=FALSE, message=FALSE}
sa_acf <- ggAcf(sa_co2_present_train$season_adjust, lag.max=(50)) + labs(title="Seasonally adjusted ACF")
sa_pacf <- ggPacf(sa_co2_present_train$season_adjust, lag.max=(50)) + labs(title="Seasonally adjusted PACF")
sa_acf / sa_pacf
```

Next, we run a KPSS test to test for stationarity, and since the pvalue is smaller than 0.05 critical value, we know the data is not stationary. We then run ndiffs to check how many differences are needed to make the data stationary. 
```{r}
sa_co2_present_train %>%
  features(season_adjust, unitroot_kpss)

sa_co2_present_train %>%
  features(season_adjust, unitroot_ndiffs)
```

From the above ndiff call, we know that there is 1 difference needed to fit the model. Assessing the ACF and PACF, the ACF has a slow decay while the PACF has a large spike at lag 1, indicating that this series has a unit root and that the process is of AR(1). Let's next difference the data once and assess the ACF and PACFs again.

```{r, echo=FALSE, message=FALSE}
sa_co2_present_train <- sa_co2_present_train %>% mutate(sa_one_diff = difference(season_adjust, 12)) 

sa_acf <- ggAcf(sa_co2_present_train$sa_one_diff, lag.max=(50)) + labs(title="Seasonally adjusted ACF 1 diff")
sa_pacf <- ggPacf(sa_co2_present_train$sa_one_diff, lag.max=(50)) + labs(title="Seasonally adjusted PACF 1 diff")

sa_acf / sa_pacf
```

Looking at the seasonally adjusted ACF and PACF, we observe a significant spike at lag 2 of the PACF before decreasing and then becoming negative at lag 12, indicating that the data is an AR(2) process. Furthermore, assessing the ACF we can see that the ACF decreases slowly and then spikes again at lag 30, all significant lags being positive, it is unclear whether an MA process is present. Let's fit a couple of candidate models to compare.

```{r, echo=FALSE, message=FALSE}
sa_our_model = Arima(sa_co2_present_train$season_adjust,order=c(2,1,0), include.drift=TRUE)
sa_our_model

sa_arima_fit = sa_co2_present_train %>% model(ARIMA(season_adjust))
report(sa_arima_fit)
```
Assessing the summaries from the model we chose to fit ARIMA(2,1,0) with drift and without a seasonal-ARIMA process, we get an $AIC = 88.79$ and $BIC = 103.08$. Furthermore, the algorithmically chosen model gave an $ARIMA(2,1,2)(2,0,0)[12]$ model, which the automatic call includes a season-ARIMA component, with $AIC = 78.13$ and $BIC = 106.71$. In either models, we see that the variances are close (0.081 vs. 0.076 respectively) and the $AIC AND BIC$ measurements are very similar for both, leading us to chose our estimated $ARIMA(2,1,0)$ model.

Now that we have our model, let's check the residuals for stationarity.
```{r, echo=FALSE, message=FALSE}
sa_resid = residuals(sa_our_model)
autoplot(sa_resid) /
ggAcf(sa_resid)
Box.test(sa_resid,lag=15, fitdf=0, type="Lj")
```
From observing the residual plot, the data loosely resembles that of white noise, while the ACF of the residuals suggests that the data is stationary as well, with a small lag spike at lag=12 and the rest of the lags within the 95% bounds. Assessing the results from the Ljung-Box test, we have a p-value that is greater than 0.05 leading us to fail to reject the null hypothesis and conclude that there is no correlation within our time series.

### Non-seasonally adjusted data assessment

Let's follow the same procedure we have above for the NSA data. Furthermore, we know there is a seasonal component to this data so let's see how many differences it will take for the data to become stationary.

Since we have assessed the ACF and PACF in the previous parts of the report, we know there is a spike at lag 2 in the PACF followed by a steep drop-off, with a slow decay in the ACF of the time series indicating there is a AR(2) process. After differencing the data, we observe that there may be a seasonal MA term but is not clear of what order.

From the below metrics we've found that 1 non-seasonal difference and 1 seasonal difference is needed.

```{r, message=FALSE, echo=FALSE}
nsa_co2_present_train %>%
  features(value, unitroot_ndiffs)

nsa_co2_present_train %>%
  features(value, unitroot_nsdiffs)
```

Now let's fit two models, same as before. One that is automatically chosen for us and another one by our assessment, which will be an $ARIMA(2,1,0)(0,1,1)[12]$ model.
```{r, message=FALSE, echo=FALSE, warning=FALSE}
nsa_our_model = Arima(nsa_co2_present_train$value, order=c(2,1,0), seasonal= list(order = c(0,1,1), period = 12))
nsa_our_model

nsa_arima_fit = nsa_co2_present_train %>% model(ARIMA(value))
report(nsa_arima_fit)
```
Observing the above summaries of both estimated models: the first output yields the model we chose to estimate with $AIC=184.51$ and $BIC=198.61$. Furthermore, the automatically generated model yields an $AIC=186.39$ and $BIC=211.07$, from this it is clear that we should use the model that we have generated: $ARIMA(2,1,0)(0,1,1)[12]$. It is interesting to note here that the ARIMA function call is supposed to yield the best fit model given a vector of criteria and loss metrics that must be optimised and minimized respectively, so it is not clear as to why the function call gave a model that has worse diagnostic metrics than our own estimated model. One reason we've thought of is the negative log-likelihood may have a higher weight in algorithmically determining the best fit model, since log likelihood of the auto ARIMA model is higher than that of the model we estimated.

Next, we should check the residuals and run tests on the model we have estimated.
```{r, echo=FALSE, message=FALSE}
nsa_resid = residuals(nsa_our_model)
autoplot(nsa_resid) /
ggAcf(nsa_resid)
Box.test(nsa_resid,lag=15, fitdf=0, type="Lj")
```
From the results of the ACF of residuals, we observe that all lags are within the significant 95% threshold which means it closely resembles that of a white noise. The time series plot of the residuals loosely resemble that of a white noise, with fluctuations floating around 0 and very rarely crossing 1 and -1. From the Ljung-Box test, we observe a p-value that is higher than 0.05 critical value, leading us to reject the null hypothesis and conclude that there is no correlation within our time series. 

From these results we will continue with using $ARIMA(2,1,0)$ for our seasonally adjusted time series, and $ARIMA(2,1,0)(0,1,1)[12]$ for our non-seasonally adjusted time series.

### Assessing model accuracy

With creating and assessing the goodness of fit of so many models, we'd also like to observe how well our models can do against our test data. In order to do so, we will measure the accuracy of our models against a test set while also observing their forecasts into the future.

* First, we create forecasts two years into the future with both models.
* Next, we will compute the accuracy measurements of both models.
* And finally, we will also train a polynomial time-trend model to the seasonally adjusted series and run the same accuracy computations as previous models.

Here are the cross validation results of the seasonally adjusted time series:
````{r, message=FALSE, echo=FALSE}
# compute predictions and assess accuracy
sa_predictions <- forecast(sa_our_model, h = 2*12+7)
sa_accuracy = accuracy(sa_predictions, sa_co2_present_test$season_adjust)
sa_accuracy
```

And below are the cross validation results of the non-seasonally adjusted time series:
````{r, message=FALSE, echo=FALSE}
# compute predictions and assess accuracy
nsa_predictions <- forecast(nsa_our_model, h = 2*12+7)
nsa_accuracy = accuracy(nsa_predictions, nsa_co2_present_test$value)
nsa_accuracy
```

And now, we will fit a polynomial time trend model to the seasonall adjusted series.
```{r, message=FALSE, echo=FALSE}

sa_fit_quadratic <- sa_co2_present_test %>%
  model(trend_model = TSLM(season_adjust ~ trend + I(trend^2)))
sa_fit_quadratic %>% report()

sa_quad_preds <- forecast(sa_fit_quadratic, h=31)
sa_quad_acc = accuracy(sa_quad_preds, sa_co2_present_test$season_adjust)
```




















